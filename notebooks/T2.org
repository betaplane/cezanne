#+EXPORT_SELECT_TAGS: export
#+BEAMER_FRAME_LEVEL: 1
#+OPTIONS: broken-links:t

* Notes
** List of original code files incorporated into this notebook:
 - bias_err_T2.py
 - bias_corr.py
 - cycles.py
 - elev2.py
 - elevations.py
 - vert_T.py
** List of files deemed outdated:
 - bias_mean.py
** List of plot files incorporated:
 - landsea.pdf
 - T2
   - daily_errors.pdf
   - annual_daily_model.pdf (i.e. annual, daily cycles based on Lomb-Scargle 'model' invocation)
   - bias_corr_bars.pdf
   - bias_corr_kde.pdf
   - bias_daily_max.pdf
   - bias_daily_min.pdf
   - bias_maps.pdf
   - bias_maps2.pdf
   - MAE_maps.pdf
   - seasonal_cycles.pdf
   - seasonal_errors.pdf
   - lapse_kde_d02.pdf
   - lapse_kde_d03orl.pdf
   - T2_elev_corr_d02.pdf
 - T
   - T_p_d02_raw_log.pdf
   - daily_diff_p_d02.pdf
** July 2017 GFS issue
*** SST (static scalar value, from wrf_operational c01 simulations)
| pre 2017-07-19 | 275.092438 |
| post           | 274.656891 |
** rutas
*** /sata1_boletin/pable/WRF_V3.8.... -> met_ files
* imports
 #+begin_src ipython :results silent :session
   import numpy as np
   import pandas as pd
   import xarray as xr
   import helpers as hh
   import matplotlib.pyplot as plt
   from matplotlib import ticker, gridspec, path
   from matplotlib.colors import Normalize
   from matplotlib.cm import ScalarMappable
   from glob import glob
   from cartopy import crs
   import plots as cplots
   # import interpolation as ip
   # import mapping as mp
   # from netCDF4 import Dataset
   # from matplotlib.figure import SubplotParams
   # from astropy.stats import LombScargle
   # from scipy.stats import gaussian_kde
   # from functools import partial
   # get_ipython().magic('matplotlib inline')
   # # rc('font', **{'family':'sans-serif','sans-serif':['Helvetica']})
   # # rc('text', usetex=True)
   # plt.rcParams.update({'text.usetex': False, 'mathtext.fontset': 'stixsans'})
   plt.style.use('~/Dropbox/spacemacs/private/nandu/stylelib/nandu_dark.mplstyle')
   coq = cplots.Coquimbo()
 #+end_src
 
** old data code
#+begin_src ipython :results silent :session
  Map = hh.basemap()

  def plot(B, cols=None, clims=None, cbars='row'):
      if cols is not None:
          B = B.loc[:, :, cols]
      if clims is None:
          cl = pd.concat((B.min(1).min(), B.max(1).max()), 1)
      for k, b in B.iteritems():
          for j, x in enumerate(B.minor_axis):
              ax = plt.subplot(B.shape[0], B.shape[2], k * B.shape[2] + j + 1)
              D = pd.concat((sta.loc[B.major_axis, ('lon', 'lat')], b[x]), axis=1).dropna()
              if k == 0:
                  ax.set_title(x)
              Map.scatter(D['lon'].as_matrix(), D['lat'].as_matrix(), c=D.iloc[:,-1], marker='o', latlon=True)
              Map.drawcoastlines()
              Map.drawparallels(range(-32, -28, 1), labels=[j==0, 0, 0, 0])
              Map.drawmeridians(range(-72, -69, 1), labels=[0, 0, 0, k==B.shape[0]-1])
              if cbars=='all':
                  plt.colorbar()
              else:
                  if clims is None:
                      plt.clim(cl[0][k], cl[1][k])
                  else:
                      try:
                          plt.clim(clims[k][0], clims[k][1])
                      except TypeError:
                          plt.clim(-clims[k], clims[k])
                  if j == B.shape[2] - 1:
                      bb = ax.get_position()
                      plt.colorbar(
                          cax=fig.add_axes([bb.x1 + 0.02, bb.y0, 0.02, bb.y1 - bb.y0]))
#+end_src

#+begin_src ipython :results silent :session
 D = pd.HDFStore('../../data/tables/station_data.h5')

 # CEAZAMet station location info
 sta = D['sta']

 # CEAZAMet station 2m temperature in K
 T = hh.stationize(D['ta_c'].xs('prom', 1, 'aggr').drop(10, 1, 'elev')) + 273.15

 S = pd.HDFStore('../../data/tables/LinearLinear.h5')

 # model 2m temperature linearly interpolated to station location
 Tm = S['T2n']

 # temperature bias (model minus stations)
 B = Tm.add( -T )

 # mean bias
 Bm = B.mean(1)

 # elevations of station locations on respective model DEMs
 Z = S['z'][[dem(z) for z in B.items]]
 Z.columns = B.items

 # elevation difference (true station elevation minus DEM)
 dz = (sta['elev'] - Z.T).T
#+end_src

* Land-Sea mask :export:
#+begin_src ipython :results raw :session :savefig "landmask.png" :exports none
  d = hh.read_hdf(LinearLinear, 'land_mask')
  fig = plt.figure(figsize=(13, 4))
  plt.set_cmap('cividis')
  plt.subplots_adjust(right=0.875)
  coq.plotrow(d)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/landmask.png]]

#+CAPTION: Linear interpolation of land (1) and sea (0) values to station locations on the various model grids.
#+RESULTS:

* elevation
#+begin_src ipython :results silent :session
  import gdal
  ds = gdal.Open({'condor': '/home/arno/Documents/data/geo/merged.tif'}[hh.config.hostname])
  g = ds.GetGeoTransform()
  b = ds.GetRasterBand(1)
  z = b.ReadAsArray()
  Z = xr.DataArray(z, coords=[
      ('lat', g[3] + g[5] * (np.arange(z.shape[0]) + .5)),
      ('lon', g[0] + g[1] * (np.arange(z.shape[1]) + .5))
  ])

  h = xr.open_dataarray({'condor': '/home/arno/Documents/data/WRF/3d/grid_d03.nc'}[hh.config.hostname]).squeeze()
  with xr.open_dataset({'condor': '/home/arno/Documents/data/WRF/3d/geo_em.d03.nc'}[hh.config.hostname]) as ds:
      sso = ds['VAR_SSO'].load().squeeze()
#+end_src


#+begin_src ipython :results silent :session
  sta = pd.read_hdf(hh.config.Meta.file_name, 'stations')
  dz = (sta['d03'] - sta['elev'].astype(float)).to_frame('dz')
#+end_src

#+begin_src ipython :results raw :session :savefig "elevation.png"
    fig = plt.figure(figsize=(15, 5))
    gs = gridspec.GridSpec(1, 12, wspace=0.2)

    lon, lat, c = pd.concat((sta[['lon', 'lat']], dz), 1).dropna().astype(float).values.T
    SM = ScalarMappable(norm=Normalize(0, max(abs(c))), cmap='binary')
    SM.set_array(abs(c))
    sm = SM.to_rgba(abs(c))
    x0, x1, y0, y1 = -72.2, -69, -32.8, -28.5
    p = path.Path([(x0, y0), (x1, y0), (x1, y1), (x0, y1), (x0, y0)])
    z = Z.sel(lat=slice(y1, y0))
    plt.set_cmap('terrain')

    a1 = fig.add_subplot(gs[1:4], projection=crs.PlateCarree())
    im = a1.imshow(z, origin='upper', transform=crs.PlateCarree(), extent=(z.lon[0], z.lon[-1], z.lat[-1], z.lat[0]))
    coq(a1, lines_only=True, colors=['w', 'k'])
    a1.set_title('SRTM')
    a1.background_patch.set_alpha(0)
    a1.outline_patch.set_edgecolor('w')
    a1.set_boundary(p)
    cplots.cbar(im, 'left', width=.02, space=.01, label='m', label_kw={'color': 'k'})
    vmin, vmax = im.get_clim()

    ax = fig.add_subplot(gs[4:7], projection=crs.PlateCarree(), sharey=a1)
    ax.pcolormesh(h.XLONG, h.XLAT, h, transform=crs.PlateCarree(), vmin=vmin, vmax=vmax)
    coq(ax, lines_only=True, colors=['w', 'k'])
    ax.set_title('HGT')
    ax.outline_patch.set_edgecolor('w')
    ax.background_patch.set_alpha(0)
    ax.set_extent((x0, x1, y0, y1))

    ax = fig.add_subplot(gs[8:11], projection=crs.PlateCarree(), sharey=a1)
    plt.set_cmap('rainbow')
    a = ax.pcolormesh(h.XLONG, h.XLAT, sso, transform=crs.PlateCarree())
    ax.scatter(lon[c<0], lat[c<0], c=sm[c<0, :], marker='^', transform=crs.PlateCarree())
    ax.scatter(lon[c>0], lat[c>0], c=sm[c>0, :], marker='v', transform=crs.PlateCarree())
    coq(ax, lines_only=True, colors=['w', 'k'])
    ax.set_title('VAR_SSO')
    ax.background_patch.set_alpha(0)
    ax.outline_patch.set_edgecolor('w')
    ax.set_extent((x0, x1, y0, y1))
    cb = cplots.cbar(a, width=.02, space=.01, label='m$^2$', label_kw={'color': 'k'})
    cb.formatter.set_scientific(True)
    cb.formatter.set_powerlimits((0, 0))
    cb.update_ticks()
    cplots.cbar(SM, 'left', ax, width=.02, space=.01, label='m')
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/elevation.png]]
#+CAPTION: DEMS from the Shuttle Radar Topography Mission (SRTM), the smoothed grid used in WRF (variable 'HGT'), and the subgridscale orographic variance after smooting (variable 'VAR_SSO'). The triangles in plot 3 (left colorbar) display the absolute value of *dz* via their color, while their orientation indicates whether the station is located lower (downward) or higher (upward) than the model grid.

* T2
** Mean bias
*** old data (up to 2016-12)
**** data
#+begin_src ipython :results silent :session
  # helper to get the correct elevation data for each model 'name'
  def dem(s):
      if s=='d03_orl': return s
      elif s[:3]=='d03': return 'd03_op'
      else: return s[:3]
  LinearLinear = {'kiwi': '../../ceaza/data/LinearLinear.h5',
                  'condor': '../../data/WRF/h5/LinearLinear.h5'}
  sta = pd.read_hdf(hh.config.Meta.file_name, 'stations')
  T = hh.stationize(pd.read_hdf(hh.config.Field.file_name, 'ta_c').drop('10', 1, 'elev')) + 273.15
  Tm = hh.read_hdf(LinearLinear, 'T2')
  B = Tm.add( -T )
  Bm = B.mean(1)
  Z = hh.read_hdf(LinearLinear, 'z')[[dem(z) for z in B.items]]
  Z.columns = B.items
  dz = Z.add(-sta['elev'].astype(float), 0) # model - station
#+end_src
**** plots
#+begin_src ipython :results raw :session :savefig "mean_bias_overview.png"
  fig = plt.figure(figsize=(14, 11))
  fig.subplots_adjust(left=0.12, right=0.86, wspace=0.06, hspace=0.06)
  x = ['d01', 'd02', 'd03_0_00', 'd03_0_12', 'd03_orl', 'fnl']
  gs = gridspec.GridSpec(3, 1)
  plt.set_cmap('Spectral')
  coq.plotrow(dz[x], subplot_spec=gs[0], vmin=-1700, vmax=1700, cbar_label='m')
  cplots.row_label(gs[0], "dz")
  plt.set_cmap('Spectral_r')
  coq.plotrow(Bm[x], subplot_spec=gs[1], vmin=-13, vmax=13, cbar_label='$^{\circ}$C')
  cplots.row_label(gs[1], "dT")
  coq.plotrow(Bm[x] + 0.0065 * dz[x], subplot_spec=gs[2], vmin=-13, vmax=13, cbar_label='$^{\circ}$C')
  cplots.row_label(gs[2], "dTc")
#+end_src

#+CAPTION: **top**: elevation bias (model DEM elevation interpolated to station location minus true station elevation)
#+CAPTION: **middle**: 2m temperature bias (model - station)  
#+CAPTION: **bottom**: temperature bias after correcting for a mean lapse rate of 6.5K / km
#+RESULTS:
[[file:./obipy-resources/T2/mean_bias_overview.png]]

#+begin_src ipython :results raw :session :savefig "mean_bias_restricted.png"
  fig = plt.figure(figsize=(10, 12))
  fig.subplots_adjust(left=0.08, right=0.86, wspace=0.06, hspace=0.06)
  x = ['d02', 'd03_orl', 'd03_0_00', 'd03_0_12']
  gs = gridspec.GridSpec(3, 1)
  plt.set_cmap('Spectral')
  coq.plotrow(dz[x], subplot_spec=gs[0], vmin=-1100, vmax=1100, cbar_label='m')
  cplots.row_label(gs[0], "dz")
  plt.set_cmap('Spectral_r')
  coq.plotrow(Bm[x], subplot_spec=gs[1], vmin=-10, vmax=10, cbar_label='$^{\circ}$C')
  cplots.row_label(gs[1], "dT")
  coq.plotrow(Bm[x] + 0.0065 * dz[x], subplot_spec=gs[2], vmin=-10, vmax=10, cbar_label='$^{\circ}$C')
  cplots.row_label(gs[2], "dTc")
#+end_src

#+CAPTION: same as above but for selected domains only (less variance for same color scales)
#+CAPTION: **top**: elevation bias (true station elevation minus model DEM elevation interpolated to station location)  
#+CAPTION: **middle**: 2m temperature bias (model - station)  
#+CAPTION: **bottom**: temperature bias after correcting for a mean lapse rate of 6.5K / km
#+RESULTS:
[[file:./obipy-resources/T2/mean_bias_restricted.png]]

*** updated data (up to 2017-07, the GFS change)
**** data
#+begin_src ipython :results silent :session
  def separate_start_hours(glob_pattern, var):
      ds = [xr.open_dataset(f)[var] for f in glob(glob_pattern)]
      n = min(len(d.Time) for d in ds)
      # using .isel() is essential b/c .sel() *includes* the end of slice
      x = xr.concat([d.isel(Time=slice(None, n)) for d in ds], 'start').sortby('start')
      h = x.start.to_index().hour
      return x.sel(start = h==20), x.sel(start = h==8)

  def lead_day(day, T_sta, ds):
      x = ds.isel(Time=slice(day*24, (day+1)*24)).stack(idx=('Time','start'))
      df = pd.DataFrame(x.values)
      if x.dims.index('station') == 0:
          df = df.T
      df.index = x.XTIME
      df.columns = x.station
      return (df - T_sta).dropna(0, 'all').resample('h').mean()

  T = hh.stationize(pd.read_hdf(hh.config.Field.file_name, 'ta_c').drop('10', 1, 'elev')) + 273.15
  sta = pd.read_hdf(hh.config.Meta.file_name, 'stations')
  dz = (sta['d03'] - sta['elev'].astype(float)).to_frame('dz')
  T2_0h, T2_12h = separate_start_hours('/nfs/HPC/arno/data/T2_*_81*', 'T2')
  # where the change in GFS occurs
  T2_12h_preJul17 = T2_12h.sel(start=slice(None, '2017-07-18'))
  T2_12h_postJul17 = T2_12h.sel(start=slice('2017-07-19', None))
  bias_0h, bias_12h = [lead_day(0, T, d) for d in [T2_0h, T2_12h]]
  bias_12h_preJul17, bias_12h_postJul17 = [lead_day(0, T, d) for d in [T2_12h_preJul17, T2_12h_postJul17]]
#+end_src

**** 0h run vs 12h runs prior to Jul 2017 (lead day 0)
#+begin_src ipython :results raw :session :savefig "mean_bias_d03_h.png"
  fig = plt.figure(figsize=(6, 7))
  fig.subplots_adjust(left=0.08, right=0.86, wspace=0.06, hspace=0.06)
  gs = gridspec.GridSpec(2, 3)
  plt.set_cmap('Spectral')
  _, gl = coq.plotrow(dz, subplot_spec=gs[0, 0], vmin=-900, vmax=900, cbar='left', cbar_label='m', cbar_width=0.03)
  gl[0].ylabels_left = False
  plt.set_cmap('Spectral_r')
  x = pd.concat((bias_0h.mean(), bias_0h.mean() + 0.0065 * dz['dz']), 1)
  x.columns = ['dT', 'dTc']
  _, gl = coq.plotrow(x, subplot_spec=gs[0, 1:], vmin=-10, vmax=10, cbar_label='$^{\circ}$C', cbar_width=0.03)
  gl[0].ylabels_left = False
  cplots.row_label(gs[0, :], "0h", labelpad=80)
  x = pd.concat((bias_12h_preJul17.mean(), bias_12h_preJul17.mean() + 0.0065 * dz['dz']), 1)
  x.columns = ['dT', 'dTc']
  coq.plotrow(x, subplot_spec=gs[1, 1:], vmin=-10, vmax=10, cbar_label='$^{\circ}$C', cbar_width=0.03)
  cplots.row_label(gs[1, :], "12h", labelpad=80)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/mean_bias_d03_h.png]]
#+CAPTION: Bias (WRF - observations) for operational domain 03 only, for the runs which were started at 0:00 UTC (**top**) and 12:00 UTC (**bottom**).
#+CAPTION: Meaning of column titles: *dz* - hight differences WRF model grid minus station elevation; *dT* - straight T2 bias; *dTc* - T2 bias 'corrected' by adjusting it for standard lapse rate times elevation difference ('dz').

**** The July 2017 issue
***** lead day 0
#+begin_src ipython :results raw :session :savefig "mean_bias_d03_12h_day0.png"
  fig = plt.figure(figsize=(6, 7))
  fig.subplots_adjust(left=0.08, right=0.86, wspace=0.06, hspace=0.06)
  gs = gridspec.GridSpec(2, 3)
  plt.set_cmap('Spectral')
  _, gl = coq.plotrow(dz, subplot_spec=gs[0, 0], vmin=-900, vmax=900, cbar='left', cbar_label='m', cbar_width=0.03)
  gl[0].ylabels_left = False
  plt.set_cmap('Spectral_r')
  x = pd.concat((bias_12h_preJul17.mean(), bias_12h_preJul17.mean() + 0.0065 * dz['dz']), 1)
  x.columns = ['dT', 'dTc']
  _, gl = coq.plotrow(x, subplot_spec=gs[0, 1:], vmin=-10, vmax=10, cbar_label='$^{\circ}$C', cbar_width=0.03)
  gl[0].ylabels_left = False
  cplots.row_label(gs[0, :], "pre", labelpad=80)
  x = pd.concat((bias_12h_postJul17.mean(), bias_12h_postJul17.mean() + 0.0065 * dz['dz']), 1)
  x.columns = ['dT', 'dTc']
  coq.plotrow(x, subplot_spec=gs[1, 1:], vmin=-10, vmax=10, cbar_label='$^{\circ}$C', cbar_width=0.03)
  cplots.row_label(gs[1, :], "post", labelpad=80)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/mean_bias_d03_12h_day0.png]]
#+CAPTION: Same as above, but for the runs starting at 12h only (from 2016-04 onward). The split is now before (**top**) and after (**bottom**) the change that occerred in the GFS at 2017-07-19.

***** lead day 1
#+begin_src ipython :results raw :session :savefig "mean_bias_d03_12h_day1.png"
  b1, b2 = [lead_day(1, T, d) for d in [T2_12h_preJul17, T2_12h_postJul17]]
  fig = plt.figure(figsize=(6, 7))
  fig.subplots_adjust(left=0.08, right=0.86, wspace=0.06, hspace=0.06)
  gs = gridspec.GridSpec(2, 3)
  plt.set_cmap('Spectral')
  _, gl = coq.plotrow(dz, subplot_spec=gs[0, 0], vmin=-900, vmax=900, cbar='left', cbar_label='m', cbar_width=0.03)
  gl[0].ylabels_left = False
  plt.set_cmap('Spectral_r')
  x = pd.concat((b1.mean(), b1.mean() + 0.0065 * dz['dz']), 1)
  x.columns = ['dT', 'dTc']
  _, gl = coq.plotrow(x, subplot_spec=gs[0, 1:], vmin=-10, vmax=10, cbar_label='$^{\circ}$C', cbar_width=0.03)
  gl[0].ylabels_left = False
  cplots.row_label(gs[0, :], "pre", labelpad=80)
  x = pd.concat((b2.mean(), b2.mean() + 0.0065 * dz['dz']), 1)
  x.columns = ['dT', 'dTc']
  coq.plotrow(x, subplot_spec=gs[1, 1:], vmin=-10, vmax=10, cbar_label='$^{\circ}$C', cbar_width=0.03)
  cplots.row_label(gs[1, :], "post", labelpad=80)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/mean_bias_d03_12h_day1.png]]
#+CAPTION: Same as above, but for lead day 1 instead of 0.

*** glacio simulation 
**** data
#+begin_src ipython :results silent :session
  def time(ds):
      ds.coords['Time'] = ('Time', ds.XTIME)
      return ds

  T = hh.stationize(pd.read_hdf(hh.config.Field.file_name, 'ta_c').drop('10', 1, 'elev')) + 273.15
  glacio_d02 = xr.open_dataarray('/nfs/HPC/arno/data/T2_glacio_d02_intp.nc')
  glacio_d03 = xr.open_dataarray('/nfs/HPC/arno/data/T2_glacio_d03_intp.nc')
  glacio = time(xr.concat((glacio_d02, glacio_d03), pd.Index(['d02', 'd03'], name='domain')))
  b = (glacio - xr.DataArray(T).rename({'ultima_lectura': 'Time'})).mean('Time')
  if b.dims.index('domain') == 0:
      bias_glacio = pd.DataFrame(b.values, index=b.domain, columns=b.station).T
  else:
      bias_glacio = pd.DataFrame(b.values, columns=b.domain, index=b.station)
  bias_glacio.columns = ['d02', 'd03']
#+end_src
**** plots
#+begin_src ipython :results raw :session :savefig "bias_glacio.png"
fig = plt.figure(figsize=(7, 4))
fig.subplots_adjust(left=0.1, right=0.9, wspace=0.06)
plt.set_cmap('Spectral')
gs = gridspec.GridSpec(1, 3)
_, gl = coq.plotrow(dz, subplot_spec=gs[0], vmin=-900, vmax=900, cbar='left', cbar_label='m', cbar_width=0.03)
gl[0].ylabels_left = False
plt.set_cmap('Spectral_r')
_, gl = coq.plotrow(bias_glacio, subplot_spec=gs[1:], vmin=-10, vmax=10, cbar_label='$^{\circ}$C', cbar_width=0.03)
gl[0].ylabels_left = False
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/bias_glacio.png]]
#+CAPTION: T2 bias as above (and height difference to the left, **dz**) for the domains **d02** and **d03** of the 'glacio' simulation (2013-03-21 - 2016-03-31).

*** seasonal biases
#+begin_src ipython :results silent :session
  def xr2pd(ds):
      x = ds.values if ds.dims.index('Time') == 0 else ds.values.T
      return pd.DataFrame(x, index=ds.Time, columns=ds.station)

  Tx = xr.DataArray(T).rename({'ultima_lectura': 'Time'})
  bias_seas = (glacio - Tx).resample('QS-MAR', 'Time', how='mean')
  bias_seas = pd.concat((
      bias_0h.resample('QS-MAR').mean(),
      bias_12h_preJul17.resample('QS-MAR').mean(),
      bias_12h_postJul17.resample('QS-MAR').mean(),
      xr2pd(bias_seas.sel(domain='d02')),
      xr2pd(bias_seas.sel(domain='d03'))
  ), keys=['0h', 'pre', 'post', 'd02', 'd03'])
  idx = bias_seas.index.get_level_values(1)
  bias_seas.index = pd.MultiIndex.from_arrays((idx.month, idx.year, bias_seas.index.get_level_values(0)))
  bias_seas = bias_seas.sort_index().unstack(0)
#+end_src
**** 2013
#+begin_src ipython :results raw :session :savefig "bias_seasonal_2013.png"
  fig = plt.figure(figsize=(8, 7))
  fig.subplots_adjust(wspace=0.04, hspace=0.04)
  gs = gridspec.GridSpec(2, 1)
  for i, (n, r) in enumerate(bias_seas.loc[2013].iterrows()):
      df = r.unstack()
      df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
      coq.plotrow(df, subplot_spec=gs[i, 0], vmin=-10, vmax=10)
      cplots.row_label(gs[i, 0], n)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/bias_seasonal_2013.png]]
#+CAPTION: Mean bias of T2 temperatures (model T2 minus station ta_c) for each season of 2013 (season *start* is counted within the year, so DJF 2013 contains January and February of 2014). The simulations are the wrf_glacio ones.

**** 2014
#+begin_src ipython :results raw :session :savefig "bias_seasonal_2014.png"
  fig = plt.figure(figsize=(8, 7))
  fig.subplots_adjust(wspace=0.04, hspace=0.04)
  gs = gridspec.GridSpec(2, 1)
  for i, (n, r) in enumerate(bias_seas.loc[2014].iterrows()):
      df = r.unstack()
      df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
      coq.plotrow(df, subplot_spec=gs[i, 0], vmin=-10, vmax=10)
      cplots.row_label(gs[i, 0], n)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/bias_seasonal_2014.png]]
#+CAPTION: Same as above, 2014.

**** 2015
#+begin_src ipython :results raw :session :savefig "bias_seasonal_2015.png"
  fig = plt.figure(figsize=(8, 10))
  fig.subplots_adjust(wspace=0.04, hspace=0.04)
  gs = gridspec.GridSpec(3, 1)
  for i, (n, r) in enumerate(bias_seas.loc[2015].loc[['d02', 'd03', '0h']].iterrows()):
      df = r.unstack()
      df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
      coq.plotrow(df, subplot_spec=gs[i, 0], vmin=-10, vmax=10)
      cplots.row_label(gs[i, 0], n)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/bias_seasonal_2015.png]]
#+CAPTION: Same as above, 2015.

**** 2016
#+begin_src ipython :results raw :session :savefig "bias_seasonal_2016.png"
  fig = plt.figure(figsize=(7, 12))
  plt.set_cmap('Spectral_r')
  fig.subplots_adjust(wspace=0.04, hspace=0.04)
  gs = gridspec.GridSpec(4, 1)
  for i, (n, r) in enumerate(bias_seas.loc[2016].loc[['d02', 'd03', '0h', 'pre']].iterrows()):
      df = r.unstack()
      df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
      coq.plotrow(df, subplot_spec=gs[i, 0], vmin=-10, vmax=10, cbar=None if i<3 else 'right')
      cplots.row_label(gs[i, 0], n)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/bias_seasonal_2016.png]]
#+CAPTION: The top two rows are from the wrf_glacio simulation (**d02** and **d03**, MAM only), the bottom two rows are from the wrf_operacional simulations (0:00 UTC start simulations, until April 2016, **0h**) and pre-July 2017 (GFS changes) 12:00 UTC simulations (**pre**).

**** 2017-18
#+begin_src ipython :results raw :session :savefig "bias_seasonal_2017-18.png"
  fig = plt.figure(figsize=(8, 10))
  fig.subplots_adjust(wspace=0.04, hspace=0.04)
  gs = gridspec.GridSpec(3, 1)
  for i, (n, r) in enumerate(bias_seas.loc[[(2017, 'pre'), (2017, 'post'), (2018, 'post')]].iterrows()):
      df = r.unstack()
      df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
      coq.plotrow(df, subplot_spec=gs[i, 0], vmin=-10, vmax=10)
      cplots.row_label(gs[i, 0], n[0], labelpad=50)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/bias_seasonal_2017-18.png]]
#+CAPTION: WRF operacional simulations, **top**: pre-July 2017 12:00 UTC simulations; **bottom**: post-July 2017. 2018 is only contained in the 'post' and contains errors from the undiscovered ground flux masking error.

*** The July 2017 issue
#+begin_src ipython :results raw :session :savefig "fnl_st_2017-07.png"
import pygrib
d = []
for g in sorted(glob('/nfs/sata1_modelosglobales/FNLs/2017_grib2/fnl_201707*')):
    f = pygrib.open(g)
    t = f[250]
    x, _, _ = t.data()
    d.append((t.validDate, x.mean()))
    f.close()

fig = plt.figure(figsize=(7, 3))
plt.plot(*zip(*d))
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/fnl_st_2017-07.png]]
#+CAPTION: global mean soil temperature around the change in GFS at 2017-07-19, in FNL data.

#+begin_src ipython :results raw :session :savefig "wrf_fnl_2017-05.png"
  import pygrib
  with pygrib.open('/nfs/sata1_modelosglobales/FNLs/2017_grib2/fnl_20170718_12_00.grib2') as f:
      st1, _, _ = f[250].data()
  with pygrib.open('/nfs/sata1_modelosglobales/FNLs/2017_grib2/fnl_20170720_12_00.grib2') as f:
      st2, lat, lon = f[250].data()

  d1 = xr.open_dataset('/nfs/sata2_glacio/wrf_glacio/c01_2017071812/wrfout_d03_2017-07-18_12:00:00')
  d2 = xr.open_dataset('/nfs/sata2_glacio/wrf_glacio/c01_2017072012/wrfout_d03_2017-07-20_12:00:00')

  fig, axs = plt.subplots(2, 2, subplot_kw={'projection': crs.PlateCarree()}, figsize=(7, 8))
  fig.subplots_adjust(wspace=0.04, hspace=0.04)
  plt.set_cmap('cividis')
  plt.sca(axs[0, 0])
  plt.pcolormesh(d1.XLONG[0,:,:], d1.XLAT[0,:,:], d1['TSK'].mean('Time'), vmin=245, vmax=290)
  coq(plt.gca(), lines_only=True)
  plt.gca().gridlines(xlocs=range(-73, -68), ylocs=range(-33, -27))
  plt.sca(axs[0, 1])
  plt.pcolormesh(d2.XLONG[0,:,:], d2.XLAT[0,:,:],d2['TSK'].mean('Time'), vmin=245, vmax=290)
  coq(plt.gca(), lines_only=True)
  plt.gca().gridlines(xlocs=range(-73, -68), ylocs=range(-33, -27))
  plt.sca(axs[1, 0])
  plt.pcolormesh(lon-.5, lat+.5, st1, transform=crs.PlateCarree(), vmin=245, vmax=290)
  coq(plt.gca(), lines_only=True)
  plt.gca().gridlines(xlocs=range(-73, -68), ylocs=range(-33, -27))
  plt.gca().set_extent(axs[0, 0].get_extent(), crs=crs.PlateCarree())
  plt.sca(axs[1, 1])
  plt.pcolormesh(lon-.5, lat+.5, st2, transform=crs.PlateCarree(), vmin=245, vmax=290)
  coq(plt.gca(), lines_only=True)
  plt.gca().gridlines(xlocs=range(-73, -68), ylocs=range(-33, -27))
  plt.gca().set_extent(axs[0, 1].get_extent(), crs=crs.PlateCarree())
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/wrf_fnl_2017-05.png]]
#+CAPTION: Two days before (**left column**) and after (**right**) the July-2017 break, in the wrf_operacional simluations (**top**) and FNL (**bottom**). The gridlines are full degrees lon/lat; the FNL plot squares are lined up **assuming that full degrees in FNL correspond to cell centers** (I don't know if that's correct). Variables shown are **TSK** (top / WRF) and soil temperature (**ts**, bottom / FNL).

** daily min/max
*** old data (up to 2016-12)
#+begin_src ipython :results raw :session :savefig "daily_min_bias_overview.png"
  x = ['fnl', 'd01', 'd02', 'd03_orl', 'd03_0_00']

  fig = plt.figure(figsize=(11, 11))
  fig.subplots_adjust(left=0.08, right=0.86, wspace=0.06, hspace=0.06)
  plt.set_cmap('Spectral_r')
  gs = gridspec.GridSpec(3, 1)

  dt = T.groupby(T.index.date).min()
  day = lambda x: x.groupby(x.major_axis.date).min()
  coq.plotrow(day(Tm[x]).add(-dt).mean(1), subplot_spec=gs[0], vmin=-10, vmax=10)
  coq.plotrow(day(Tm[x].add(0.0065 * dz[x], 1)).add(-dt).mean(1), subplot_spec=gs[1], vmin=-10, vmax=10)
  coq.plotrow(day(Tm[x].add(-Bm[x], 1)).add(-dt).mean(1), subplot_spec=gs[2], vmin=-10, vmax=10)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/daily_min_bias_overview.png]]
#+CAPTION: **top**: mean bias of daily **minimum** temperatures (model minus station)  
#+CAPTION: **middle**: mean bias after correction for mean lapse rate of 6.5K / km  
#+CAPTION: **bottom**: mean bias of daily minimum after removing mean bias (over all records)


#+begin_src ipython :results raw :session :savefig "daily_max_bias_overview.png"
  x = ['fnl', 'd01', 'd02', 'd03_orl', 'd03_0_00']

  fig = plt.figure(figsize=(11, 11))
  fig.subplots_adjust(left=0.08, right=0.86, wspace=0.06, hspace=0.06)
  plt.set_cmap('Spectral_r')
  gs = gridspec.GridSpec(3, 1)

  dt = T.groupby(T.index.date).max()
  day = lambda x: x.groupby(x.major_axis.date).max()
  coq.plotrow(day(Tm[x]).add(-dt).mean(1), subplot_spec=gs[0], vmin=-10, vmax=10)
  coq.plotrow(day(Tm[x].add(0.0065 * dz[x], 1)).add(-dt).mean(1), subplot_spec=gs[1], vmin=-10, vmax=10)
  coq.plotrow(day(Tm[x].add(-Bm[x], 1)).add(-dt).mean(1), subplot_spec=gs[2], vmin=-10, vmax=10)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/daily_max_bias_overview.png]]
#+CAPTION: **top**: mean bias of daily **maximum** temperatures (model minus station)  
#+CAPTION: **middle**: mean bias after correction for mean lapse rate of 6.5K / km  
#+CAPTION: **bottom**: mean bias of daily maximum after removing mean bias (over all records)

*** updated data (seasonal)
**** daily min
#+begin_src ipython :results silent :session
  from WuRF.base import tease_apart

  def xr2pd(ds):
      x = ds.values if ds.dims.index('station') == 1 else ds.values.T
      return pd.DataFrame(x, index=getattr(ds, (set(ds.dims) - {'station'}).pop()), columns=ds.station)

  def lead_day(day, ds):
      x = ds.isel(Time=slice(day*24, (day+1)*24)).stack(idx=('Time','start'))
      x.coords['idx'] = ('idx', x.XTIME)
      return x.rename({'idx': 'Time'})

  T = hh.stationize(pd.read_hdf(hh.config.Field.file_name, 'ta_c').drop('10', 1, 'elev')) + 273.15
  Tx = xr.DataArray(T).rename({'ultima_lectura': 'Time'})
  T_min = day('min', Tx)

  T2_0h, T2_12h = tease_apart('/nfs/HPC/arno/data/T2_*_81*', 'T2')
  bias_0h, bias_12h = [xr2pd(day('min', lead_day(1, d)) - T_min) for d in [T2_0h, T2_12h]]
  bias_seas = (day('min', glacio) - T_min).resample('QS-MAR', 'day', how='mean')
  bias_seas = pd.concat((
      bias_0h.resample('QS-MAR').mean(),
      bias_12h.resample('QS-MAR').mean(),
      xr2pd(bias_seas.sel(domain='d02')),
      xr2pd(bias_seas.sel(domain='d03'))
  ), keys=['0h', '12h', 'd02', 'd03'])
  idx = bias_seas.index.get_level_values(1)
  bias_seas.index = pd.MultiIndex.from_arrays((idx.month, idx.year, bias_seas.index.get_level_values(0)))
  bias_seas = bias_seas.sort_index().unstack(0)
#+end_src


#+begin_src ipython :results raw :session :savefig "daily_min_bias_large.png"
  fig = plt.figure(figsize=(8, 17))
  lg = gridspec.GridSpec(7, 2, left=0.05, right=1., wspace=0.05, hspace=0.15, bottom=.15)
  plt.set_cmap('Spectral_r')
  subplot_kw = {'wspace': 0.01}

  for y, year in enumerate([2013, 2014]):
      gs = gridspec.GridSpecFromSubplotSpec(2, 1, lg[:2, y], hspace=0.01)
      for i, (n, r) in enumerate(bias_seas.loc[year].iterrows()):
          df = r.unstack()
          df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
          coq.plotrow(df, subplot_spec=gs[i, 0], vmin=-10, vmax=10, cbar=None, xlabels=False, ylabels=False, subplot_kw=subplot_kw)
          if y==0: cplots.row_label(gs[i], n, labelpad=20)
      cplots.bottom_label(lg[1, y], year)

  for y, year in enumerate([2015, 2016]):
      gs = gridspec.GridSpecFromSubplotSpec(4, 1, lg[2:6, y], hspace=0.01)
      for i, n in enumerate(['d02', 'd03', '0h', '12h']):
          try:
              df = bias_seas.loc[(year, n)].unstack()
          except: pass
          else:
              df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
              coq.plotrow(df, subplot_spec=gs[i, 0], vmin=-10, vmax=10, cbar=None, xlabels=False, ylabels=False, title=False, subplot_kw=subplot_kw)
          if y==0: cplots.row_label(gs[i], n, labelpad=20)
      cplots.bottom_label(lg[5, y], year)
  df = bias_seas.loc[(2017, '12h')].unstack()
  df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
  coq.plotrow(df, subplot_spec=lg[6, 0], vmin=-10, vmax=10, cbar=None, xlabels=False, ylabels=False, title=False, subplot_kw=subplot_kw)
  ax = cplots.row_label(lg[6, 0], '12h', labelpad=20)
  cplots.bottom_label(ax, 2017)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/daily_min_bias_large.png]]
#+CAPTION: Bias of daily minimum T2 temperature by season and year, for the various simulations available. The individual plots correspond to those in [[seasonal biases]].
**** daily max
#+begin_src ipython :results silent :session
  T_max = day('max', Tx)
  bias_0h, bias_12h = [xr2pd(day('max', lead_day(1, d)) - T_max) for d in [T2_0h, T2_12h]]
  bias_seas = (day('max', glacio) - T_max).resample('QS-MAR', 'day', how='mean')
  bias_seas = pd.concat((
      bias_0h.resample('QS-MAR').mean(),
      bias_12h.resample('QS-MAR').mean(),
      xr2pd(bias_seas.sel(domain='d02')),
      xr2pd(bias_seas.sel(domain='d03'))
  ), keys=['0h', '12h', 'd02', 'd03'])
  idx = bias_seas.index.get_level_values(1)
  bias_seas.index = pd.MultiIndex.from_arrays((idx.month, idx.year, bias_seas.index.get_level_values(0)))
  bias_seas = bias_seas.sort_index().unstack(0)
#+end_src

#+begin_src ipython :results raw :session :savefig "daily_max_bias_large.png"
  fig = plt.figure(figsize=(8, 17))
  lg = gridspec.GridSpec(7, 2, left=0.05, right=1., wspace=0.05, hspace=0.15, bottom=.15)
  plt.set_cmap('Spectral_r')
  subplot_kw = {'wspace': 0.01}

  for y, year in enumerate([2013, 2014]):
      gs = gridspec.GridSpecFromSubplotSpec(2, 1, lg[:2, y], hspace=0.01)
      for i, (n, r) in enumerate(bias_seas.loc[year].iterrows()):
          df = r.unstack()
          df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
          coq.plotrow(df, subplot_spec=gs[i, 0], vmin=-10, vmax=10, cbar=None, xlabels=False, ylabels=False, subplot_kw=subplot_kw)
          if y==0: cplots.row_label(gs[i], n, labelpad=20)
      cplots.bottom_label(lg[1, y], year)

  for y, year in enumerate([2015, 2016]):
      gs = gridspec.GridSpecFromSubplotSpec(4, 1, lg[2:6, y], hspace=0.01)
      for i, n in enumerate(['d02', 'd03', '0h', '12h']):
          try:
              df = bias_seas.loc[(year, n)].unstack()
          except: pass
          else:
              df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
              coq.plotrow(df, subplot_spec=gs[i, 0], vmin=-10, vmax=10, cbar=None, xlabels=False, ylabels=False, title=False, subplot_kw=subplot_kw)
          if y==0: cplots.row_label(gs[i], n, labelpad=20)
      cplots.bottom_label(lg[5, y], year)
  df = bias_seas.loc[(2017, '12h')].unstack()
  df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
  coq.plotrow(df, subplot_spec=lg[6, 0], vmin=-10, vmax=10, cbar=None, xlabels=False, ylabels=False, title=False, subplot_kw=subplot_kw)
  ax = cplots.row_label(lg[6, 0], '12h', labelpad=20)
  cplots.bottom_label(ax, 2017)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/daily_max_bias_large.png]]
#+CAPTION: Same as above, for bias of daily maximum.

** Mean absolute error (MAE)
*** old data (up to 2016-12)
#+begin_src ipython :results raw :session :savefig "MAE_overview.png"
  x = ['fnl', 'd01', 'd02', 'd03_orl', 'd03_0_00', 'd03_0_12']

  fig = plt.figure(figsize=(9, 7))
  fig.subplots_adjust(left=0.08, right=0.86, wspace=0.06, hspace=0.06)
  plt.set_cmap('cividis')
  gs = gridspec.GridSpec(3, 1)

  coq.plotrow(abs(B[x]).mean(1), subplot_spec=gs[0], vmin=0, vmax=10)
  coq.plotrow(abs(B[x].add(0.0065 * dz[x], 1)).mean(1), subplot_spec=gs[1], vmin=0, vmax=10)
  coq.plotrow(abs(B[x].add(-Bm[x], 1)).mean(1), subplot_spec=gs[2], vmin=0, vmax=5)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/MAE_overview.png]]
#+CAPTION: **top**: mean absolute error (MAE) of 2m temperature (model/station)  
#+CAPTION: **middle**: MAE after correction for mean lapse rate of 6.5K / km  
#+CAPTION: **bottom**: MAE after removal of mean bias

*** updated data (seasonal)
#+begin_src ipython :results silent :session
  bias_0h, bias_12h = [xr2pd(abs(lead_day(1, d) - Tx)) for d in [T2_0h, T2_12h]]
  bias_seas = abs(glacio - Tx).resample('QS-MAR', 'Time', how='mean')
  bias_seas = pd.concat((
      bias_0h.resample('QS-MAR').mean(),
      bias_12h.resample('QS-MAR').mean(),
      xr2pd(bias_seas.sel(domain='d02')),
      xr2pd(bias_seas.sel(domain='d03'))
  ), keys=['0h', '12h', 'd02', 'd03'])
  idx = bias_seas.index.get_level_values(1)
  bias_seas.index = pd.MultiIndex.from_arrays((idx.month, idx.year, bias_seas.index.get_level_values(0)))
  bias_seas = bias_seas.sort_index().unstack(0)
#+end_src

#+begin_src ipython :results raw :session :savefig "MAE_seasonal.png"
  fig = plt.figure(figsize=(8, 17))
  lg = gridspec.GridSpec(7, 2, left=0.05, right=1., wspace=0.05, hspace=0.15, bottom=.15)
  plt.set_cmap('cividis')
  subplot_kw = {'wspace': 0.01}

  for y, year in enumerate([2013, 2014]):
      gs = gridspec.GridSpecFromSubplotSpec(2, 1, lg[:2, y], hspace=0.01)
      for i, (n, r) in enumerate(bias_seas.loc[year].iterrows()):
          df = r.unstack()
          df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
          coq.plotrow(df, subplot_spec=gs[i, 0], vmin=0, vmax=10, cbar=None, xlabels=False, ylabels=False, subplot_kw=subplot_kw)
          if y==0: cplots.row_label(gs[i], n, labelpad=20)
      cplots.bottom_label(lg[1, y], year)

  for y, year in enumerate([2015, 2016]):
      gs = gridspec.GridSpecFromSubplotSpec(4, 1, lg[2:6, y], hspace=0.01)
      for i, n in enumerate(['d02', 'd03', '0h', '12h']):
          try:
              df = bias_seas.loc[(year, n)].unstack()
          except: pass
          else:
              df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
              coq.plotrow(df, subplot_spec=gs[i, 0], vmin=0, vmax=10, cbar=None, xlabels=False, ylabels=False, title=False, subplot_kw=subplot_kw)
          if y==0: cplots.row_label(gs[i], n, labelpad=20)
      cplots.bottom_label(lg[5, y], year)
  df = bias_seas.loc[(2017, '12h')].unstack()
  df.columns = [{3: 'MAM', 6: 'JJA', 9: 'SON', 12: 'DJF'}[k] for k in df.columns]
  coq.plotrow(df, subplot_spec=lg[6, 0], vmin=0, vmax=10, cbar=None, xlabels=False, ylabels=False, title=False, subplot_kw=subplot_kw)
  ax = cplots.row_label(lg[6, 0], '12h', labelpad=20)
  cplots.bottom_label(ax, 2017)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/MAE_seasonal.png]]

** error evolution with simulation time
#+begin_src ipython :results silent :session
from WuRF.base import align_stations
err_0h, err_12h = [d - align_stations(d, T) for d in [T2_0h, T2_12h]]

T_raw = hh.stationize(hh.read_hdf({'condor': '/nfs/HPC/arno/data/station_raw_binned_middle.h5'}, 'ta_c').drop('10', 1, 'elev'), 'avg') + 273.15
raw_0h, raw_12h = [d - align_stations(d, T_raw) for d in [T2_0h, T2_12h]]
#+end_src

#+begin_src ipython :results raw :session :savefig "error_evolution.png"
fig, axs = plt.subplots(2, 1)
plt.sca(axs[0])
plt.plot(err_0h.mean(('start', 'station')), label='0h')
plt.plot(err_12h.mean(('start', 'station')), label='12h')
plt.plot(raw_0h.mean(('start', 'station')), label='0h raw')
plt.plot(raw_12h.mean(('start', 'station')), label='12h raw')
plt.legend(loc=1)

plt.sca(axs[1])
plt.plot(abs(err_0h).mean(('start', 'station')), label='0h')
plt.plot(abs(err_12h).mean(('start', 'station')), label='12h')
plt.plot(abs(raw_0h).mean(('start', 'station')), label='0h raw')
plt.plot(abs(raw_12h).mean(('start', 'station')), label='12h raw')
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/error_evolution.png]]
#+CAPTION: **Top** - Bias, **bottom** - MAE of model error against hour of the simulation, for the wrf_operacional simulations. The lines labeled 'raw' use for comparison the 'raw' station data binned to hourly intervals *centered* on the given timestamp (it is relatively difficult to say what the non-raw station data timestamps correspond to). **Note** that the bump appearing in the morning is more pronounced in the raw-binned data (its existing in the non-raw data prompted me to see if it would disappear with 'raw' ones - what *could* be involved is the morning boundary layer breakup).

** different ways of correcting for lapse rate
*** exploration
#+begin_src ipython :results silent :session
lapse_rate = xr.open_dataarray('/nfs/HPC/arno/data/lapse_2015-18.nc').squeeze() 
corr = xr.DataArray(dz).squeeze() * lapse_rate
#+end_src

#+begin_src ipython :results raw :session
d = T2_0h - corr
corr_0h = d - align_stations(d, T)
fig = plt.figure()
plt.plot(err_0h.mean(('start', 'station')))
plt.plot(corr_0h.mean(('start', 'station')))
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/XIU0WG.png]]

#+begin_src ipython :results silent :session
  import runpy
  from WuRF.base import tease_apart, align_stations

  table = runpy.run_path('/home/arno/Dropbox/spacemacs/private/nandu/pandas2org.py')['table']

  def day(op, ds):
      x = ds.copy()
      x.coords['day'] = ('Time', pd.DatetimeIndex(x.indexes['Time'].date))
      return getattr(x.groupby('day'), op)('Time')

  def daily_err(sl, ds, T_sta):
      x = ds.isel(Time=sl)
      return (x - align_stations(x, T_sta)).dropna('station', 'all')

  def d(name, a, b):
      x = abs(a - b).mean('Time')
      return pd.DataFrame(x.values, index=x.station, columns=[name])

  def shift(ds, h):
      return ds.isel(Time=np.r_[range(h, 24), range(h)])
#+end_src

#+begin_src ipython :results raw :session
  x = pd.concat((d('t1',
                   daily_err(slice(28, 52), T2_0h, T).mean('start'),
                   daily_err(slice(16, 40), T2_12h, T).mean('start')),
                 d('t2',
                   daily_err(slice(4, 28), T2_0h, T).mean('start'),
                   daily_err(slice(16, 40), T2_12h, T).mean('start')),
                 d('t3',
                   daily_err(slice(28, 52), T2_0h, T).mean('start'),
                   daily_err(slice(40, 64), T2_12h, T).mean('start')),
                 d('s1',
                   shift(daily_err(slice(0, 24), T2_0h, T).mean('start'), 4),
                   shift(daily_err(slice(0, 24), T2_12h, T).mean('start'), 16)),
                 d('s2',
                   shift(daily_err(slice(24, 48), T2_0h, T).mean('start'), 4),
                   shift(daily_err(slice(24, 48), T2_12h, T).mean('start'), 16)),
                 d('s3',
                   shift(daily_err(slice(48, 72), T2_0h, T).mean('start'), 4),
                   shift(daily_err(slice(48, 72), T2_12h, T).mean('start'), 16))), 1)

  table(x.mean().to_frame('mean'))
#+end_src

#+RESULTS:
|    |          mean |
|----+---------------|
| t1 | 1.91327879208 |
| t2 | 2.27730736175 |
| t3 | 2.10255406442 |
| s1 | 2.20754349586 |
| s2 | 2.01088312773 |
| s3 | 1.96309657704 |

#+begin_src ipython :results raw :session :savefig "daily_err_0vs12h.png"
fig = plt.figure(figsize=(11, 3))
plt.set_cmap('cividis')
coq.plotrow(x, vmin=0, vmax=5, subplot_kw={'wspace': .04})
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/daily_err_0vs12h.png]]
#+CAPTION: Different ways of comparing the 0:00 and 12:00 UTC starting runs w.r.t daily cycles of errors: since the simulations are shifted by 12 hours, comparing daily cycles directly requires some form of shifting of the resulting outputs. All procedures select 24 hours per simulation ('start' date). The plots labelled 't...' use different simulation timesteps which correspond to the same daily times (starting at 0:00); the plots labelled 's...' use the same simulation timesteps, but shift the resulting 24-hour blocks so that they align to cycles starting at 0:00.

#+begin_src ipython :results silent :session
T = hh.stationize(pd.read_hdf(hh.config.Field.file_name, 'ta_c').drop('10', 1, level='elev')) + 273.15
T2_0h, T2_12h = tease_apart('/nfs/HPC/arno/data/T2_*_81*', 'T2')

err_0h = daily_err(slice(28, 52), T2_0h, T).mean('start')
err_12h = daily_err(slice(16, 40), T2_12h, T).mean('start')
#+end_src

#+begin_src ipython :results raw :session
  fig, axs = plt.subplots(2, 1)
  axs[0].plot(err_0h.values.T)
  axs[1].plot(err_12h.values.T)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/Es71rX.png]]
#+begin_src ipython :results raw :session :savefig "daily_err_cycle_2clusters.png"
  from sklearn import cluster
  from matplotlib.colors import Normalize
  from matplotlib.cm import ScalarMappable

  n_clusters = 2
  fig = plt.figure(figsize=(9, 7))
  gs = gridspec.GridSpec(2, n_clusters+1, wspace=0.06, hspace=0.06)
  sm = ScalarMappable(norm=Normalize(0, 9), cmap='tab10')

  km = cluster.KMeans(n_clusters=n_clusters)
  km_0h, km_12h = [km.fit_predict((d - d.mean('Time')).values) for d in [err_0h, err_12h]] 

  for i in range(n_clusters):
      share = {} if i==0 else {'sharey': ax}
      ax = plt.subplot(gs[0, i], **share)
      ax.plot(err_0h.sel(station=km_0h==i).values.T)
      ax.set_xticks([0, 12])
      ax.set_xticklabels([])
      if i>0:
          plt.setp(ax.get_yticklabels(), visible=False) # workaround for shared axes
# see  https://stackoverflow.com/questions/4209467/matplotlib-share-x-axis-but-dont-show-x-axis-tick-labels-for-both-just-one
  coq.plotrow(pd.DataFrame(km_0h, index=err_0h.station), gs[0, n_clusters], title=False, xlabels=False, ylabels=False, cbar=None, norm=sm)
  cplots.add_axes(gs[0, n_clusters]).legend(
      [ax.scatter([], [], s=70, facecolors=sm.to_rgba(i)) for i in range(n_clusters)],
      range(n_clusters), loc=2, bbox_to_anchor=(1, 1)
  )

  for i in range(n_clusters):
      ax = plt.subplot(gs[1, i], sharey=ax)
      ax.plot(err_12h.sel(station=km_12h==i).values.T)
      ax.set_xticks([0, 12])
      if i>0:
          plt.setp(ax.get_yticklabels(), visible=False)
  coq.plotrow(pd.DataFrame(km_12h, index=err_12h.station), gs[1, n_clusters], title=False, xlabels=False, ylabels=False, cbar=None, norm=sm)
  cplots.add_axes(gs[1, n_clusters]).legend(
      [ax.scatter([], [], s=70, facecolors=sm.to_rgba(i)) for i in range(n_clusters)],
      range(n_clusters), loc=2, bbox_to_anchor=(1, 1)
  )
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/daily_err_cycle_2clusters.png]]
#+CAPTION: Daily cycle of errors, by station, clustered with KMeans into 2 classes. Maps show the clusters in the same integer order in which they appear as line plots on the left. X-axes are the hours of the day, local time. **Top** - the 0:00 UTC simulations (prior to 2016-04); **bottom** - the 12:00 UTC simulations (after 2016-04).

#+begin_src ipython :results raw :session :savefig "daily_err_cycle_3clusters.png"
  n_clusters = 3
  fig = plt.figure(figsize=(9, 5))
  gs = gridspec.GridSpec(2, n_clusters+1, wspace=0.06, hspace=0.06)
  sm = ScalarMappable(norm=Normalize(0, 9), cmap='tab10')

  km = cluster.KMeans(n_clusters=n_clusters)
  km_0h, km_12h = [km.fit_predict((d - d.mean('Time')).values) for d in [err_0h, err_12h]] 

  for i in range(n_clusters):
      share = {} if i==0 else {'sharey': ax}
      ax = plt.subplot(gs[0, i], **share)
      ax.plot(err_0h.sel(station=km_0h==i).values.T)
      ax.set_xticks([0, 12])
      ax.set_xticklabels([])
      if i>0:
          plt.setp(ax.get_yticklabels(), visible=False)
  coq.plotrow(pd.DataFrame(km_0h, index=err_0h.station), gs[0, n_clusters], title=False, xlabels=False, ylabels=False, cbar=None, norm=sm)
  cplots.add_axes(gs[0, n_clusters]).legend(
      [ax.scatter([], [], s=70, facecolors=sm.to_rgba(i)) for i in range(n_clusters)],
      range(n_clusters), loc=2, bbox_to_anchor=(1, 1)
  )

  for i in range(n_clusters):
      ax = plt.subplot(gs[1, i], sharey=ax)
      ax.plot(err_12h.sel(station=km_12h==i).values.T)
      ax.set_xticks([0, 12])
      if i>0:
          plt.setp(ax.get_yticklabels(), visible=False)
  coq.plotrow(pd.DataFrame(km_12h, index=err_12h.station), gs[1, n_clusters], title=False, xlabels=False, ylabels=False, cbar=None, norm=sm)
  cplots.add_axes(gs[1, n_clusters]).legend(
      [ax.scatter([], [], s=70, facecolors=sm.to_rgba(i)) for i in range(n_clusters)],
      range(n_clusters), loc=2, bbox_to_anchor=(1, 1)
  )
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/daily_err_cycle_3clusters.png]]
#+CAPTION: Same as above, for 3 clusters.

#+begin_src ipython :results raw :session :savefig "daily_err_cycle_raw_2clusters.png"
  T_raw = hh.stationize(hh.read_hdf({'condor': '/nfs/HPC/arno/data/station_raw_binned_middle.h5'}, 'ta_c').drop('10', 1, level='elev'), 'avg') + 273.15

  err_0h = daily_err(slice(28, 52), T2_0h, T_raw).mean('start')
  err_12h = daily_err(slice(16, 40), T2_12h, T_raw).mean('start')
  km = cluster.KMeans(n_clusters=n_clusters)
  km_0h, km_12h = [km.fit_predict((d - d.mean('Time')).values) for d in [err_0h, err_12h]] 

  n_clusters = 2
  fig = plt.figure(figsize=(9, 7))
  gs = gridspec.GridSpec(2, n_clusters+1, wspace=0.06, hspace=0.06)
  sm = ScalarMappable(norm=Normalize(0, 9), cmap='tab10')


  for i in range(n_clusters):
      share = {} if i==0 else {'sharey': ax}
      ax = plt.subplot(gs[0, i], **share)
      ax.plot(err_0h.sel(station=km_0h==i).values.T)
      ax.set_xticks([0, 12])
      ax.set_xticklabels([])
      if i>0:
          plt.setp(ax.get_yticklabels(), visible=False)
  coq.plotrow(pd.DataFrame(km_0h, index=err_0h.station), gs[0, n_clusters], title=False, xlabels=False, ylabels=False, cbar=None, norm=sm)
  cplots.add_axes(gs[0, n_clusters]).legend(
      [ax.scatter([], [], s=70, facecolors=sm.to_rgba(i)) for i in range(n_clusters)],
      range(n_clusters), loc=2, bbox_to_anchor=(1, 1)
  )

  for i in range(n_clusters):
      ax = plt.subplot(gs[1, i], sharey=ax)
      ax.plot(err_12h.sel(station=km_12h==i).values.T)
      ax.set_xticks([0, 12])
      if i>0:
          plt.setp(ax.get_yticklabels(), visible=False)
  coq.plotrow(pd.DataFrame(km_12h, index=err_12h.station), gs[1, n_clusters], title=False, xlabels=False, ylabels=False, cbar=None, norm=sm)
  cplots.add_axes(gs[1, n_clusters]).legend(
      [ax.scatter([], [], s=70, facecolors=sm.to_rgba(i)) for i in range(n_clusters)],
      range(n_clusters), loc=2, bbox_to_anchor=(1, 1)
  )
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/daily_err_cycle_raw_2clusters.png]]
#+CAPTION: Same as above, for 2 clusters, but with raw-binned station data.

#+begin_src ipython :results silent :session
  from sklearn import cluster

  T2m = xr.open_dataarray('/nfs/HPC/arno/data/T2MEAN.nc')
  T_raw = hh.stationize(hh.read_hdf({'condor': '/nfs/HPC/arno/data/station_raw_binned_end.h5'}, 'ta_c').drop('10', 1, level='elev'), 'avg') + 273.15
  e0 = daily_err(slice(16, 40), T2m, T_raw)
  err = e0.mean('start').transpose('station', 'Time')
  sta = pd.read_hdf(hh.config.Meta.file_name, 'stations')
  dz = (sta['d03'] - sta['elev'].astype(float)).to_frame('dz')
#+end_src


#+begin_src ipython :results raw :session :savefig "daily_err_cycle_raw_mean_2clusters.png"
  n_clusters = 2
  km = cluster.KMeans(n_clusters=n_clusters).fit_predict((err - err.mean('Time')).values)

  fig = plt.figure(figsize=(8, 3))
  gs = gridspec.GridSpec(1, n_clusters+1, wspace=0.06)
  sm = ScalarMappable(norm=Normalize(0, 9), cmap='tab10')

  for i in range(n_clusters):
      share = {} if i==0 else {'sharey': ax}
      ax = plt.subplot(gs[i], **share)
      ax.plot(err.sel(station=km==i).values.T)
      ax.set_xticks([0, 12])
      ax.set_xticklabels([])
      if i>0:
          plt.setp(ax.get_yticklabels(), visible=False)
  coq.plotrow(pd.DataFrame(km, index=err.station), gs[n_clusters], title=False, xlabels=False, ylabels=False, cbar=None, norm=sm)
  cplots.add_axes(gs[n_clusters]).legend(
      [ax.scatter([], [], s=70, facecolors=sm.to_rgba(i)) for i in range(n_clusters)],
      range(n_clusters), loc=2, bbox_to_anchor=(1, 1)
  )
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/daily_err_cycle_raw_mean_2clusters.png]]
#+CAPTION: Same as above, but for the accumulated mean T2 values instead of point values ('wrfxtrm...' files), and raw data binned to 'end' of intervals.

#+begin_src ipython :results raw :session :savefig "dz_vs_sso_clusters.png"
  df = pd.concat((dz, sta['d03_var_sso'], pd.Series(km, index=err.station, name='km')), 1).dropna()
  sm = ScalarMappable(norm=Normalize(0, 9), cmap='tab10')

  fig, axs = plt.subplots(1, 3, figsize=(9, 3))
  axs[0].scatter(df['dz'], df['km'], c=sm.to_rgba(df['km']))
  axs[0].set_xlabel('dz')
  axs[1].scatter(df['d03_var_sso'], df['km'], c=sm.to_rgba(df['km']))
  axs[1].set_xlabel('sso')
  axs[2].scatter(df['dz'], df['d03_var_sso'] ** .5, c=sm.to_rgba(df['km']))
  axs[2].yaxis.set_label_position('right')
  axs[2].yaxis.set_ticks_position('right')
  axs[2].set_xlabel('dz')
  axs[2].set_ylabel('$\sqrt{sso}$', usetex=True)
  x = axs[2].get_ylim()
  axs[2].plot(x, x, color='w')
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/dz_vs_sso_clusters.png]]
#+CAPTION: **Left two** plots: cluster label (0, 1) against **dz** (grid minus station elevation) and **sso** (subgridscale orographic variance, 'VAR_SSO' in the 'geo_em...' files). **Right:** $\sqrt{sso}$ against dz, with 1-1 diagonal.

#+begin_src ipython :results raw :session :savefig "PiscoElqui_daily_cycle.png"
  fig = plt.figure(figsize=(10,5))
  t1 = T2_12h.sel(station='8', Time=slice(16, 39)).stack(t=('Time','start')).sortby('XTIME')
  t2 = T2m.sel(station='8', Time=slice(16, 39)).stack(t=('Time','start')).sortby('XTIME')

  colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

  plt.plot(T['8'], label='station regular')
  plt.plot(T_raw['8'], label='station raw')
  plt.plot(t1.XTIME, t1, label='model regular')
  plt.plot(t2.XTIME, t2, label='model mean')
  plt.gca().set_xlim('2017-02-05', '2017-02-10')
  plt.gca().set_ylim(270, 305)
  plt.legend(loc=9)

  dt1 = pd.Series(t1.values, index=t1.XTIME) - T['8']
  dt2 = pd.Series(t2.values, index=t2.XTIME) - T_raw['8']
  bx = plt.twinx()
  plt.plot(dt1.index, dt1, color=colors[4], label='error regular')
  plt.plot(dt2.index, dt2, color=colors[5], label='error raw')
  bx.set_ylim(-10, 25)
  plt.legend(loc=8)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/PiscoElqui_daily_cycle.png]]

#+CAPTION: Example data for a few days from Pisco Elqui ('8'). Model data is bilinearly interpolated to station location. 'Regular' refers, for the data, to the direct database retrieval for a given timestamp, whereas 'raw' refers to manual binning with timestamp referring to the end of the binning interval (1 hour in this case). For the model, 'mean' refers to the accumulated and averaged data (in the 'wrfxtrm...' files), rather than the time-point values (which are the default for WRF output). For the error (right y-axis), 'regular' refers to 'model regular' minus 'station regular', whereas 'raw' refers to 'model mean' minus 'station raw'.

#+begin_src ipython :results raw :session :savefig "topo_scatter_err_minmax.png"
  fig, axs = plt.subplots(2, 2, figsize=(10, 10))
  fig.subplots_adjust(wspace=0.05)

  e1 = err - err.mean('Time')
  df = pd.concat((sta, dz, pd.DataFrame(e1.max('Time').values, index=e1.station, columns=['dmax']),
                  pd.DataFrame(e1.min('Time').values, index=e1.station, columns=['dmin'])), 1).dropna()
  elev = df['elev'].astype(float)
  sm = ScalarMappable(norm=Normalize(elev.min(), elev.max()), cmap='spring').to_rgba(elev)
  met = df[df.index.str.contains('MET')]

  axs[0, 0].scatter(df.d03_var_sso, df.dmax, c=sm)
  axs[0, 0].scatter(met.d03_var_sso, met.dmax, edgecolor='lime', facecolor='none', marker='o', s=70)
  axs[0, 0].set_ylabel('$(\Delta T)_{max}$', usetex=True)
  axs[0, 0].set_xlabel('var_sso')
  axs[0, 0].xaxis.get_major_formatter().set_powerlimits((0, 0))

  axs[0, 1].scatter(df.d03_var_sso, df.dmin, c=sm)
  axs[0, 1].scatter(met.d03_var_sso, met.dmin, edgecolor='lime', facecolor='none', marker='o', s=70)
  axs[0, 1].set_ylabel('$(\Delta T)_{min}$', usetex=True)
  axs[0, 1].set_xlabel('var_sso')
  axs[0, 1].yaxis.set_ticks_position('right')
  axs[0, 1].yaxis.set_label_position('right')
  axs[0, 1].xaxis.get_major_formatter().set_powerlimits((0, 0))

  axs[1, 0].scatter(df.dz, df.d03_var_sso**.5, c=sm)
  axs[1, 0].scatter(met.dz, met.d03_var_sso**.5, edgecolor='lime', facecolor='none', marker='o', s=70)
  axs[1, 0].set_xlabel('dz')
  axs[1, 0].set_ylabel('$\sqrt{sso}$', usetex=True)
  axs[1, 1].scatter(elev, df.d03_var_sso**.5, c=sm)
  axs[1, 1].scatter(met.elev.astype(float), met.d03_var_sso**.5, edgecolor='lime', facecolor='none', marker='o', s=70)
  axs[1, 1].set_xlabel('elev')
  axs[1, 1].set_yticklabels([])
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/topo_scatter_err_minmax.png]]
#+CAPTION: Maximum and minimum errors of the average daily cycle against subgridscale orographic variance ('var_sso') (**top** row). The **bottom** row plots the square root of *var_sso* against the model-station elevation difference (**dz**, **left**) and station elevation (**right**). The colors correspond to station elevation (as in plot 4). The lime-circle points mark the stations in the Huasco valley ('MET...'), which appear as outliers in many analyses. My supsicion is that it has to do with the orientation of the valley and the precise geometry of the station location. The two stations with the highest *var_sso* are Pisco Elqui and Rivadavia ('8' and 'PYRV'), whose valley is oriented N-S.

#+begin_src ipython :results raw :session :savefig "topo_scatter_err_minmax_dz.png"
  fig, axs = plt.subplots(1, 2, figsize=(10, 5))
  fig.subplots_adjust(wspace=0.05)

  e1 = err - err.mean('Time')
  df = pd.concat((sta, dz, pd.DataFrame(e1.max('Time').values, index=e1.station, columns=['dmax']),
                  pd.DataFrame(e1.min('Time').values, index=e1.station, columns=['dmin'])), 1).dropna()
  dz = df['dz'].astype(float)
  sm = ScalarMappable(norm=Normalize(dz.min(), dz.max()), cmap='spring').to_rgba(dz)
  met = df[df.index.str.contains('MET')]

  axs[0].scatter(df.d03_var_sso, df.dmax, c=sm)
  axs[0].scatter(met.d03_var_sso, met.dmax, edgecolor='lime', facecolor='none', marker='o', s=70)
  axs[0].set_ylabel('$(\Delta T)_{max}$', usetex=True)
  axs[0].set_xlabel('var_sso')
  axs[0].xaxis.get_major_formatter().set_powerlimits((0, 0))

  axs[1].scatter(df.d03_var_sso, df.dmin, c=sm)
  axs[1].scatter(met.d03_var_sso, met.dmin, edgecolor='lime', facecolor='none', marker='o', s=70)
  axs[1].set_ylabel('$(\Delta T)_{min}$', usetex=True)
  axs[1].set_xlabel('var_sso')
  axs[1].xaxis.get_major_formatter().set_powerlimits((0, 0))
  axs[1].yaxis.set_ticks_position('right')
  axs[1].yaxis.set_label_position('right')
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/topo_scatter_err_minmax_dz.png]]
#+CAPTION: Same as (top row) above, but now the color corresponds to **dz** (third plot).

#+begin_src ipython :results silent :session
  from functools import singledispatch

  def xr2pd(ds):
      x = ds.values if ds.dims.index('station') == 1 else ds.values.T
      return pd.DataFrame(x, index=getattr(ds, (set(ds.dims) - {'station'}).pop()), columns=ds.station)

  @singledispatch
  def day(ds, op):
      x = ds.copy()
      x.coords['day'] = ('t', pd.DatetimeIndex(x.indexes['t'].date))
      return xr2pd(getattr(x.groupby('day'), op)('t'))
  @day.register(pd.DataFrame)
  def _(ds, op):
      return day(xr.DataArray(ds).rename({'dim_0': 't'}), op)
  
  t0 = T2m.isel(Time=slice(16, 40)).stack(t=('Time', 'start')).sortby('XTIME')
  t0.coords['t']=('t', t0.XTIME)
  err_min = day(t0, 'min') - day(T_raw, 'min')
  err_max = day(t0, 'max') - day(T_raw, 'max')
  df = pd.concat((dz, sta, err_min.mean(), err_max.mean()), 1).dropna()
#+end_src

#+begin_src ipython :results raw :session :savefig "topo_scatter_minmax_err.png"
  fig = plt.figure(figsize=(10, 10))
  gs = gridspec.GridSpec(2, 2, wspace=.05, hspace=.05)

  met = df[df.index.str.contains('MET')]
  elev = df['elev'].astype(float)
  sm = ScalarMappable(norm=Normalize(elev.min(), elev.max()), cmap='spring').to_rgba(elev)

  ax = fig.add_subplot(gs[0, 0])
  ax.scatter(df.d03_var_sso, df[0], c=sm)
  ax.scatter(met.d03_var_sso, met[0], edgecolor='lime', facecolor='none', marker='o', s=70)
  ax.set_xticklabels([])
  ax.set_ylabel('$\Delta (T_{min})$', usetex=True)

  ax = fig.add_subplot(gs[0, 1], sharey=ax)
  ax.scatter(df.d03_var_sso, df[1], c=sm)
  ax.scatter(met.d03_var_sso, met[1], edgecolor='lime', facecolor='none', marker='o', s=70)
  ax.set_xticklabels([])
  ax.yaxis.set_ticks_position('right')
  ax.yaxis.set_label_position('right')
  ax.set_ylabel('$\Delta (T_{max})$', usetex=True)

  dz = df['dz'].astype(float)
  sm = ScalarMappable(norm=Normalize(dz.min(), dz.max()), cmap='spring').to_rgba(dz)
  met = df[df.index.str.contains('MET')]
  ax = fig.add_subplot(gs[1, 0])
  ax.scatter(df.d03_var_sso, df[0], c=sm)
  ax.scatter(met.d03_var_sso, met[0], edgecolor='lime', facecolor='none', marker='o', s=70)
  ax.xaxis.get_major_formatter().set_powerlimits((0, 0))
  ax.set_xlabel('var_sso')
  ax.set_ylabel('$\Delta (T_{min})$', usetex=True)

  ax = fig.add_subplot(gs[1, 1], sharey=ax)
  ax.scatter(df.d03_var_sso, df[1], c=sm)
  ax.scatter(met.d03_var_sso, met[1], edgecolor='lime', facecolor='none', marker='o', s=70)
  ax.xaxis.get_major_formatter().set_powerlimits((0, 0))
  ax.yaxis.set_ticks_position('right')
  ax.yaxis.set_label_position('right')
  ax.set_xlabel('var_sso')
  ax.set_ylabel('$\Delta (T_{max})$', usetex=True)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/topo_scatter_minmax_err.png]]
#+CAPTION: Errors of daily maximum and minimum T2 temperatures (as opposed to daily maximum and minimum of errors, as above) against subgridscale orographic variance ('var_sso'). The color in the **top** panel corresponds to station elevation, in the **bottom** panel to 'dz' (model grid minus station elevation).

#+begin_src ipython :results silent :session
  lapse_rate = xr.open_dataarray('/nfs/HPC/arno/data/lapse_2015-18.nc').squeeze() 
  T2_12h_corr = T2_12h - xr.DataArray(dz).squeeze() * lapse_rate
  T2_12h_drad = T2_12h + xr.DataArray(dz).squeeze() * 0.0098 # dry adiabatic lapse rate
  T_raw = hh.stationize(hh.read_hdf({'condor': '/nfs/HPC/arno/data/station_raw_binned_middle.h5'}, 'ta_c').drop('10', 1, level='elev'), 'avg') + 273.15
#+end_src

#+begin_src ipython :results raw :session :savefig "PiscoElqui_daily_cycle_corr.png"
  fig = plt.figure(figsize=(10,5))
  tc = T2_12h_corr.sel(station='8', Time=slice(16, 39)).stack(t=('Time','start')).sortby('XTIME')
  td = T2_12h_drad.sel(station='8', Time=slice(16, 39)).stack(t=('Time','start')).sortby('XTIME')

  colors = plt.rcParams['axes.prop_cycle'].by_key()['color']

  plt.plot(T['8'], label='station regular')
  plt.plot(T_raw['8'], label='station raw')
  plt.plot(tc.XTIME, tc, label='model')
  plt.plot(td.XTIME, td, label='model dry adiabatic')
  plt.gca().set_xlim('2017-02-05', '2017-02-10')
  plt.gca().set_ylim(275, 310)
  plt.legend(loc=9)

  dt1 = pd.Series(tc.values, index=tc.XTIME)
  dt2 = dt1 - T_raw['8']
  dt1 = dt1 - T['8']
  bx = plt.twinx()
  plt.plot(dt1.index, dt1, color=colors[4], label='error regular')
  plt.plot(dt2.index, dt2, color=colors[5], label='error raw')
  bx.set_ylim(-5, 30)
  plt.legend(loc=8)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/PiscoElqui_daily_cycle_corr.png]]
#+CAPTION: Example daily cycle as above, for Pisco Elqui ('8'), but with the model data corrected by using the temperature difference between the lowest two model levels as an approximation to the boundary layer lapse rate and multiplying it with the difference between model grid and station elevations ('dz'). NOTE: I use the point-value model output here since I have only computed accumulated (mean) values for T2, not T (which is needed for the lapse rate). To be consistent, I therefore use the point-values for both; for that reason, I also use the 'T_raw' station data with time labels in the 'middle' of binning intervals.

#+begin_src ipython :results raw :session :savefig "mean_min_max_bias_corr.png"
  T2 = T2_12h.isel(Time=slice(16, 40)).stack(t=('Time', 'start'))
  T2.coords['t'] = T2.XTIME
  bias_seas = pd.concat((
      (xr2pd(T2) - T_raw).resample('QS-MAR').mean(),
      (day(T2, 'min') - day(T_raw, 'min')).resample('QS-MAR').mean(),
      (day(T2, 'max') - day(T_raw, 'max')).resample('QS-MAR').mean()
      ), keys=['mean', 'min', 'max']).xs(slice('2016-06', '2017-03'), 0, 1, False)

  T2c = T2_12h_corr.isel(Time=slice(16, 40)).stack(t=('Time', 'start'))
  T2c.coords['t'] = T2c.XTIME
  bias_seas_corr = pd.concat((
      (xr2pd(T2c) - T_raw).resample('QS-MAR').mean(),
      (day(T2c, 'min') - day(T_raw, 'min')).resample('QS-MAR').mean(),
      (day(T2c, 'max') - day(T_raw, 'max')).resample('QS-MAR').mean()
      ), keys=['mean', 'min', 'max']).xs(slice('2016-06', '2017-03'), 0, 1, False)

  fig = plt.figure(figsize=(9, 6))
  plt.set_cmap('Spectral_r')
  gs = gridspec.GridSpec(3, 2)
  subplot_kw = {'wspace': 0.01}
  for i, m in enumerate(['mean', 'min', 'max']):
      for j, b in enumerate([bias_seas, bias_seas_corr]):
          df = b.loc[m].T
          df.columns = ['JJA', 'SON', 'DJF', 'MAM']
          coq.plotrow(df, gs[i, j], vmin=-10, vmax=10,  cbar=None, xlabels=False, ylabels=False, subplot_kw=subplot_kw)
      cplots.row_label(gs[i, 0], m, labelpad=20)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/mean_min_max_bias_corr.png]]
#+CAPTION: Mean bias of daily mean, minimum and maximum T2 temperatures from 2016-06 to 2017-05, by season. **Left** - without correction; **right** - corrected by using the difference between the air temperatures of the first two model layers as an approximation to the time-varying lapse rate.

#+begin_src ipython :results raw :session :savefig "mean_min_max_bias_drad.png"
  T2c = T2_12h_drad.isel(Time=slice(16, 40)).stack(t=('Time', 'start'))
  T2c.coords['t'] = T2c.XTIME
  bias_seas_mean = pd.concat((
      (xr2pd(T2c) - T_raw).resample('QS-MAR').mean(),
      (day(T2c, 'min') - day(T_raw, 'min')).resample('QS-MAR').mean(),
      (day(T2c, 'max') - day(T_raw, 'max')).resample('QS-MAR').mean()
      ), keys=['ave', 'min', 'max']).xs(slice('2016-06', '2017-03'), 0, 1, False)

  bias_seas_MAE = pd.concat((
      abs(xr2pd(T2c) - T_raw).resample('QS-MAR').mean(),
      abs(day(T2c, 'min') - day(T_raw, 'min')).resample('QS-MAR').mean(),
      abs(day(T2c, 'max') - day(T_raw, 'max')).resample('QS-MAR').mean()
      ), keys=['ave', 'min', 'max']).xs(slice('2016-06', '2017-03'), 0, 1, False)

  fig = plt.figure(figsize=(9, 6))
  gs = gridspec.GridSpec(3, 2)
  subplot_kw = {'wspace': 0.01}
  for i, m in enumerate(['ave', 'min', 'max']):
      for j, b in enumerate([bias_seas_mean, bias_seas_MAE]):
          plt.set_cmap(['Spectral_r', 'cividis'][j])
          df = b.loc[m].T
          df.columns = ['JJA', 'SON', 'DJF', 'MAM']
          coq.plotrow(df, gs[i, j], vmin=[-10, 0][j], vmax=10,  cbar=None, xlabels=False, ylabels=False, subplot_kw=subplot_kw)
      cplots.row_label(gs[i, 0], m, labelpad=20)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/mean_min_max_bias_drad.png]]
#+CAPTION: Bias (**left**) and absolute (**right**) error versions of the T2 seasonal errors from 2016-06 to 2017-05, corrected with the **dry adiabatic lapse rate**.


#+begin_src ipython :results raw :session :savefig "MEA_min_max_corr.png"
  T2 = T2_12h.isel(Time=slice(16, 40)).stack(t=('Time', 'start'))
  T2.coords['t'] = T2.XTIME
  bias_seas = pd.concat((
      abs(xr2pd(T2) - T_raw).resample('QS-MAR').mean(),
      abs(day(T2, 'min') - day(T_raw, 'min')).resample('QS-MAR').mean(),
      abs(day(T2, 'max') - day(T_raw, 'max')).resample('QS-MAR').mean()
      ), keys=['MAE', 'min', 'max']).xs(slice('2016-06', '2017-03'), 0, 1, False)

  T2c = T2_12h_corr.isel(Time=slice(16, 40)).stack(t=('Time', 'start'))
  T2c.coords['t'] = T2c.XTIME
  bias_seas_corr = pd.concat((
      abs(xr2pd(T2c) - T_raw).resample('QS-MAR').mean(),
      abs(day(T2c, 'min') - day(T_raw, 'min')).resample('QS-MAR').mean(),
      abs(day(T2c, 'max') - day(T_raw, 'max')).resample('QS-MAR').mean()
      ), keys=['MAE', 'min', 'max']).xs(slice('2016-06', '2017-03'), 0, 1, False)

  fig = plt.figure(figsize=(9, 6))
  plt.set_cmap('cividis')
  gs = gridspec.GridSpec(3, 2)
  subplot_kw = {'wspace': 0.01}
  for i, m in enumerate(['MAE', 'min', 'max']):
      for j, b in enumerate([bias_seas, bias_seas_corr]):
          df = b.loc[m].T
          df.columns = ['JJA', 'SON', 'DJF', 'MAM']
          coq.plotrow(df, gs[i, j], vmin=0, vmax=10,  cbar=None, xlabels=False, ylabels=False, subplot_kw=subplot_kw)
      cplots.row_label(gs[i, 0], m, labelpad=20)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/MEA_min_max_corr.png]]
#+CAPTION: Same as above, but for MAE.

#+begin_src ipython :results silent :session
  err = daily_err(slice(16, 40), T2_12h_corr, T_raw).mean('start')
  e1 = err - err.mean('Time')
  df = pd.concat((dz, sta,
      pd.DataFrame(e1.max('Time').values, index=e1.station, columns=['dmax']),
      pd.DataFrame(e1.min('Time').values, index=e1.station, columns=['dmin']),
      (day(T2c, 'min') - day(T_raw, 'min')).mean(),
      (day(T2c, 'max') - day(T_raw, 'max')).mean()
  ), 1).dropna()
#+end_src


#+begin_src ipython :results raw :session
  fig = plt.figure(figsize=(10, 10))
  gs = gridspec.GridSpec(2, 2, wspace=.05, hspace=.05)

  met = df[df.index.str.contains('MET')]
  elev = df['elev'].astype(float)
  sm = ScalarMappable(norm=Normalize(elev.min(), elev.max()), cmap='spring').to_rgba(elev)

  ax = fig.add_subplot(gs[0, 0])
  ax.scatter(df.d03_var_sso, df['dmin'], c=sm)
  ax.scatter(met.d03_var_sso, met['dmin'], edgecolor='lime', facecolor='none', marker='o', s=70)
  ax.set_xticklabels([])
  ax.set_ylabel('$(\Delta T)_{min}$', usetex=True)

  ax = fig.add_subplot(gs[0, 1], sharey=ax)
  ax.scatter(df.d03_var_sso, df['dmax'], c=sm)
  ax.scatter(met.d03_var_sso, met['dmax'], edgecolor='lime', facecolor='none', marker='o', s=70)
  ax.set_xticklabels([])
  ax.yaxis.set_ticks_position('right')
  ax.yaxis.set_label_position('right')
  ax.set_ylabel('($\Delta T)_{max}$', usetex=True)

  # dz = df['dz'].astype(float)
  # sm = ScalarMappable(norm=Normalize(dz.min(), dz.max()), cmap='spring').to_rgba(dz)
  ax = fig.add_subplot(gs[1, 0])
  ax.scatter(df.d03_var_sso, df[0], c=sm)
  ax.scatter(met.d03_var_sso, met[0], edgecolor='lime', facecolor='none', marker='o', s=70)
  ax.xaxis.get_major_formatter().set_powerlimits((0, 0))
  ax.set_xlabel('var_sso')
  ax.set_ylabel('$\Delta (T_{min})$', usetex=True)

  ax = fig.add_subplot(gs[1, 1], sharey=ax)
  ax.scatter(df.d03_var_sso, df[1], c=sm)
  ax.scatter(met.d03_var_sso, met[1], edgecolor='lime', facecolor='none', marker='o', s=70)
  ax.xaxis.get_major_formatter().set_powerlimits((0, 0))
  ax.yaxis.set_ticks_position('right')
  ax.yaxis.set_label_position('right')
  ax.set_xlabel('var_sso')
  ax.set_ylabel('$\Delta (T_{max})$', usetex=True)
#+end_src

#+RESULTS:
[[file:./obipy-resources/T2/9dMi4O.png]]
*** Notes
**** Using dry adiabatic lapse rate gives one of the better corrections for the daily maximum temperatures, at least inland.
***** consistent with well-mixed, dry boundary layer at mid-day
***** in the Pisco Elqui valley, the PBL parameterization underestimates the correction, the dry lapse rate is better (for daily max)
**** The same is not true for minimum temperatures, as to be expected.
***** During the night, stratification occurs and an inversion may be produced.
**** At the coast, where *dz* is not very large, there is not much difference between corrections
**** The model-based correction doesn't do well for minimum temps in winter in the Pisco Elqui valley
**** Both corrections seem to make things generally worse for minimum temperatures, except in winter in the Pisco Elqui valley with the dry adiabatic lapse rate (and there's a still slight cold bias).
** Skewness & kurtosis
   
#+begin_src ipython :results silent :session
 x = ['fnl', 'd01', 'd02', 'd03_orl', 'd03_0_00', 'd03_0_12']

 fig = plt.figure(
     figsize=(14,6),
     subplotpars=SubplotParams(left=0.08, right=0.86, wspace=0.06, hspace=0.06))
 plt.set_cmap('coolwarm')

 P = pd.Panel({
     0: B.skew(1),
     1: B.add( -0.0065 * dz, 1 ).skew(1),
 })

 plot(P, cols=x, clims=[1, 1])
#+end_src

**Note:** There are outliers in the data (viz. **CT, MARIP**) which show up only in comparison with those model runs with which they overlap in time (viz. d03_orl, fnl).
    
#+begin_src ipython :results silent :session
 x = ['fnl', 'd01', 'd02', 'd03_orl', 'd03_0_00', 'd03_0_12']

 fig = plt.figure(
     figsize=(14, 6),
     subplotpars=SubplotParams(left=0.08, right=0.86, wspace=0.06, hspace=0.06))
 plt.set_cmap('coolwarm')

 P = pd.Panel({
     0: B.kurt(1),
     1: B.add( -0.0065 * dz, 1 ).kurt(1)
 })

 plot(P, cols=x, clims=[1, 1])
#+end_src


**Note:** Kurtosis computed by pandas is obviously standardized (-3).

** Cycles
   
#+begin_src ipython :results silent :session
  # This gives a good current approximation to the solar year length in seconds
  def pow(d, T=np.timedelta64(1, 'Y').astype('timedelta64[s]'), return_period=False):
      f = lambda k: k.astype(float)
      try:
          c = d.dropna()
          t = np.array(c.index, dtype='datetime64[s]')
          n = np.arange(t[0], t[0]+T, dtype='datetime64[h]').astype('datetime64[s]')
          if (t[-1] - t[0]) < T / 4: return np.nan
          x = c.as_matrix()
          y = LombScargle(f(t), x).model(f(n), f(T)**-1)
          return pd.Timestamp(n[y.argmax()]).month if return_period else max(y) - min(y)
      except:
          return np.nan
#+end_src

#+begin_src ipython :results silent :session
  x = ['obs', 'fnl', 'd01', 'd02', 'd03_orl', 'd03_0_00']

  fig = plt.figure(
      figsize=(15, 7),
      subplotpars=SubplotParams(left=.1, right=.96, bottom=.06, top=.92, wspace=.1, hspace=.1))
  plt.set_cmap('gnuplot')

  d = dict(Tm)
  d['obs'] = T
  d = pd.Panel(d)
  std = d.groupby(d.major_axis.month).std()
  std.major_axis = std.major_axis.astype('datetime64[M]')

  P = pd.Panel({
      0: d.apply(pow, 1),
      1: std.mean(1),
      2: std.apply(pow, 1)
  })

  plot(P, cols=x, cbars='all')
#+end_src

#+CAPTION: **top**: amplitude of annual cycle in 2m temperatures for observations and models (peak-to-peak, $2 \hat{U}$)  
#+CAPTION: **middle**: mean monthly standard deviation of 2m temperatures  
#+CAPTION: **bottom**: amplitude of annual cycle (as above) of monthly standard deviation
#+CAPTION: **Note**: The annual cycle is computed from a Lomb-Scargle periodogram, as this is known to work reliably even for lengths of records of only a fraction of the period under investigation. The amplitude is computed from the model reconstruction of the astropy.stats.LombScargle algorithm, since the normalization of the Lomb-Scargle periodogram is not directly related to that of a Fourier transform.

#+begin_src ipython :results silent :session
  x = ['fnl', 'd01', 'd02', 'd03_orl', 'd03_0_00']

  fig = plt.figure(
      figsize=(15, 6),
      subplotpars=SubplotParams(left=.1, right=.96, bottom=.06, top=.92, wspace=.1, hspace=.1))
  plt.set_cmap('gnuplot')

  std = B.groupby(B.major_axis.month).std()
  std.major_axis = std.major_axis.astype('datetime64[M]')

  P = pd.Panel({
      0: B.apply(pow, 1),
      1: std.apply(pow, 1)
  })

  plot(P, cols=x, cbars='all')
#+end_src

#+CAPTION: **top**: amplitude of annual cycle (see above) of 2m temperature **bias** (model minus station)  
#+CAPTION: **bottom**: amplitude of annual cycle of monthly standard deviation of temperature bias


#+begin_src ipython :results silent :session
  x = ['obs', 'fnl', 'd01', 'd02', 'd03_orl', 'd03_0_00']

  fig = plt.figure(
      figsize=(15, 3),
      subplotpars=SubplotParams(left=.1, right=.96, bottom=.06, top=.92, wspace=.12, hspace=.1))
  plt.set_cmap('hsv')

  plot(pd.Panel({0: d.apply(pow, 1, return_period=True)}), cols=x, clims=[(1,12)])
#+end_src

#+CAPTION: **Phase** of annual cycle of 2m temperatures (as month 1-12), computed from Lomb-Scargle reconstrution


#+begin_src ipython :results silent :session
  x = ['obs', 'fnl', 'd01', 'd02', 'd03_orl', 'd03_0_00']

  fig = plt.figure(
      figsize=(15, 6),
      subplotpars=SubplotParams(left=.1, right=.96, bottom=.06, top=.92, wspace=.1, hspace=.1))
  plt.set_cmap('gnuplot')

  P = pd.Panel({
      0: d.apply(pow, 1),
      1: d.apply(pow, 1, T=np.timedelta64(1, 'D').astype('timedelta64[s]')),
  })

  plot(P, cols=x)
#+end_src

#+CAPTION: **top**: amplitude of annual cycle (see above) of 2m temperatures  
#+CAPTION: **bottom**: amplitude of daily cycle, computed in the same way

** Kernel density estimates (KDE) of errors
#+begin_src ipython :results silent :session
   # compute values of 2x2 contingency table (a, b, c, d)
   def abcd(df):
       m = df.notnull().astype(int)
       n = df.shape[0]
       a = np.where(m.sum(axis=1)==2)[0].shape[0]
       b,c = [np.where(m.diff(axis=1)[1]==i)[0].shape[0] for i in [1,-1]]
       d = n-a-b-c
       return a,b,c,d,n

   x = np.linspace(-20,20,100)

   P = [Tm, Tm.add(-0.0065 * dz, 1), Tm.add(-Bm, 1), Tm.add(-B.apply(lambda x:x.rolling('7D').mean(), 1))]

   cols = np.array([['fnl','d01','d02'],['d03_orl','d03_0_00','d03_0_12'],['d03_0_00','d03_1_00','d03_4_00']])
   fig,axs = plt.subplots(*cols.shape, figsize=(15, 10))
   mae = np.zeros(np.r_[cols.shape,4])
   cold = np.zeros_like(mae)
   heat = np.zeros_like(mae)
   for i, row in enumerate(cols):
       for j, s in enumerate(row):
           plt.sca(axs[i,j])
           axs[i,j].set_title(cols[i,j])

           for h,f in enumerate(P):
               y = f[s]-T
               fg = f[s].groupby(f[s].index.date)
               Tg = T.groupby(T.index.date)
               mae[i,j,h] = abs(y).mean().mean()
               k = gaussian_kde(y.stack().dropna())

               p = pd.Panel({0: Tg.min(), 1:fg.min()}).to_frame()
               a,b,c,d,n = abcd(p[p<hh.K])
               cold[i,j,h] = a/(a+b+c)

               p = pd.Panel({0: Tg.max(), 1:fg.max()}).to_frame()
               a,b,c,d,n = abcd(p[p>hh.K+30])
               heat[i,j,h] = a/(a+b+c)
               plt.plot(x,k(x))

           plt.grid()
        
   for ax in axs.flatten():
       ax.set_ylim(0,0.2)
       ax.set_yticklabels([])

   for ax in axs[:2,:].flatten():
       ax.set_xticklabels([])
#+end_src

#+begin_src ipython :results raw :session
dz
#+end_src


#+begin_src ipython :results raw :session
k = gaussian_kde(B['d03_0_00']['MARPCH'].dropna())
#+end_src


#+begin_src ipython :results raw :session
x = np.linspace(-20,20,100)
plt.plot(x,k(x))
#+end_src


#+CAPTION: Kernel-density estimates of error distributions for various domains/models.
#+CAPTION: **blue**: no correction  
#+CAPTION: **yellow**: mean lapse rate of 6.5$^{\circ}$K km$^{-1}$  
#+CAPTION: **green**: mean bias removed  
#+CAPTION: **red**: 7-day moving average of bias removed

1. The heavy tail on the *cold* bias side (model too cold w.r.t data) is ameliorated when correcting for a mean lapse rate of 6.5 $^{\circ}$K km$^{-1}$.
2. However, the error around the mode of the distribution is worsened. **Does this mean some stations are located in permanently stable conditions?**
3. The changes due to lapse rate correction obviously become smaller for higher grid resolution.
4. Removal of mean bias (overall or moving) appears to shift the error distribution towards normal. However, the error (see MAE above) on a per-station basis increases. 
5. The difference between static and moving mean corrections diminishes for finer grids. **Does this suggest improved dynamics?**


#+begin_src ipython :results silent :session
  fig,axs = plt.subplots(*cols.shape, figsize=(15, 10))
  cy = axs[0,0]._get_lines.prop_cycler
  col = [next(cy)['color'] for i in range(4)]
  x = np.arange(4)
  for i in range(cols.shape[0]):
      for j in range(cols.shape[1]):
          axs[i,j].set_title(cols[i,j])
          plt.sca(axs[i,j])
          p = np.r_[mae[i:i+1,j],cold[i:i+1,j],heat[i:i+1,j]]
          plt.bar(x,p[0,:],color=col)
          axs[i,j].set_ylim((0,5.1))
          ax = axs[i,j].twinx()
          ax.bar(x+5,p[1,:],color=col)
          ax.bar(x+10,p[2,:],color=col)
          ax.set_ylim((0,0.81))
          axs[i,j].set_xticks([1.5,6.5,11.5])
          if i==2: axs[i,j].set_xticklabels(['MAE','TS < 0C', 'TS > 30C'])
          else: axs[i,j].set_xticklabels([])
          if j>0: axs[i,j].set_yticklabels([])
          if j<2: ax.set_yticklabels([])
          if i==1:
              if j==0: axs[1,0].set_ylabel('MAE')
              if j==2: ax.set_ylabel('threat score (TS)')
#+end_src


#+CAPTION: MAE and threat score cite:wilks_statistical_2006 (page 263) of two scenarios:
#+CAPTION: 1. Daily minimum below 0$^{\circ}$C ('< 0C')
#+CAPTION: 2. Daily maximum above 30$^{\circ}$C ('> 30C')
#+CAPTION: **blue**: without correction  
#+CAPTION: **yellow**: with lapse rate 6.5K/km correction  
#+CAPTION: **green**: with mean bias removed  
#+CAPTION: **red**: with one-week running mean bias removed  
#+CAPTION: **Note**: Threat score of 1 is perfect, 0 is worst. Gives proportion of correct 'yes' forcasts of events after removing 'no' forcasts from consideration. 

#+begin_src ipython :results silent :session
D.close()
S.close()
#+end_src

#+begin_src ipython :results silent :session
  g3 = Dataset('../../data/WRF/3d/geo_em.d03.nc')
  Map = mp.basemap(g3)
  lm = g3.variables['LANDMASK'][0,:,:]
  g3.close()

  n0 = Dataset('../../data/WRF/3d/d03_day0.nc')
  x0 = ip.nc_interp(n0, 'T2', sta, method='linear', map=Map)
  j = hh.tsplit(x0)
  n0.close()

  x0_1 = x0.iloc[:j,:]
  x0_2 = x0.iloc[j:,:]

  n4 = Dataset('../../data/WRF/3d/T2_4.nc')
  x4 = ip.nc_interp(n4, 'T2', sta, method='linear', map=Map)
  x4_1 = x4.iloc[:j,:]
  x4_2 = x4.iloc[j:,:]
  x4.close()

  fig = plt.figure(figsize=(12,8))
  for i,x in enumerate([Tm['d03_orl'],x0_1,x0_2,x4_1,x4_2]):
      y = (x-T)**2
      y = y.groupby(y.index.hour).mean().mean(1)
      plt.plot(y,label=['orl','op+0/00','op+0/12','op+4/00','op+4/12'][i])
  plt.legend()
  plt.grid()
  xt = plt.gca().set_xticks(range(0,24,2))
#+end_src

#+CAPTION: Mean error stratified by hour of the day for selected experiments.
#+CAPTION: *Legend*
#+CAPTION: **orl**: Orlando's domain
#+CAPTION: **op**: forcast domain 3
#+CAPTION: **+a/b**: a - forecast lead time in days, b - initialization hour of GFS forecast

#+begin_src ipython :results silent :session
  from scipy.optimize import brute
  from pyproj import Geod

  L = -B.divide(dz, 1) * 1000

  def landsea(r, lm, lonlat, d=5000):
      inv = partial(Geod(ellps='WGS84').inv,r['lon'],r['lat'])
      def dist(x,y):
          return inv(x,y)[2]
      dv = np.vectorize(dist)
      return np.any(1-lm[np.where(dv(*lonlat)<d)])

  def partition(sea, dz):
      """
      dz = station - grid
      returns [above, a-inland, a-coast, below, b-inland, b-coast]

      """
      a = set(dz[dz>0].index) # -> station "a"bove grid level
      b = set(dz[dz<0].index) # -> station "b"elow grid level
      b_s = b.intersection(sea)
      a_s = a.intersection(sea)
      return [list(s) for s in (a, a-a_s, a_s, b, b-b_s, b_s)]

  def kplot(y,label,bw=0.1):
      x = np.linspace(-20,20,100)
      k = gaussian_kde(y.stack().dropna(),bw)
      m = brute(lambda z:-k(z),((-20,10),))
      plt.plot(x,k(x),label='{}: {:.2f}'.format(label,m[0]))
      return m[0]

  def mode(y,bw=0.1):
      k = gaussian_kde(y.stack().dropna(),bw)
      m = brute(lambda z:-k(z),((-20,10),))
      return m[0]

  def topplot(ax, ab):
      plt.sca(ax)
      plt.axvline(-9.8, color='grey', ls='--')
      plt.axvline(-6.5, color='grey', ls=':')
      plt.grid()   
      plt.title('station ${}$ grid'.format(ab))
      plt.gca().set_xlabel('$\Delta$T')

  def botplot(ax, a=None, b=None, lab=None):
      plt.sca(ax)
      if a is not None:
          plt.plot(a.groupby(a.index.hour).apply(mode), label='all')
          plt.plot(b.groupby(b.index.hour).apply(mode), label=lab)
          plt.legend()
      plt.gca().set_xticks([0,6,12,18])
      plt.axhline(-9.8, color='grey',ls='--')
      plt.axhline(-6.5, color='grey',ls=':')
      plt.grid()
      plt.gca().set_xlabel('hour')
      plt.gca().set_ylabel('$\Delta$T')


  g3 = Dataset('../../data/WRF/3d/geo_em.d03.nc')
  landmask = g3.variables['LANDMASK'][0,:,:]
  lonlat = hh.lonlat(g3)
  sea = sta[sta.apply(landsea, 1, lm=landmask, lonlat=lonlat)].index
  g3.close()
#+end_src

#+begin_src ipython :results silent :session
  a, a_l, a_s, b, b_l, b_s = partition(sea, dz['d02'])
  lr = L['d02']

  fig, axs = plt.subplots(2, 2, figsize=(15,10)) 

  topplot(axs[0, 0], '<')
  kplot(lr[b],'all')
  kplot(lr[b_l],'inland all')
  kplot(lr[b_l][lr.index.hour==0],'inland 0h')
  kplot(lr[b_l][lr.index.hour==12],'inland 12h')
  plt.legend()

  topplot(axs[0, 1], '>')
  kplot(lr[a_l],'inland all', .001)
  kplot(lr[a_l][lr.index.hour==0],'inland 0h', .001)
  kplot(lr[a_l][lr.index.hour==12],'inland 12h', .001)
  kplot(lr[a_s],'coast all')
  kplot(lr[a_s][lr.index.hour==0],'coast 0h')
  kplot(lr[a_s][lr.index.hour==12],'coast 12h')
  plt.legend()

  botplot(axs[1, 1])
  plt.plot(lr[a].groupby(lr.index.hour).apply(lambda z:mode(z,.005)), label='all')
  plt.plot(lr[a_l].groupby(lr.index.hour).apply(lambda z:mode(z,.001)), label='inland')
  plt.plot(lr[a_s].groupby(lr.index.hour).apply(mode), label='coast')
  plt.legend()

  botplot(axs[1, 0], lr[b], lr[b_l], 'inland')
#+end_src

#+CAPTION: 'Hypothetical' lapse rates arising from model errors: Model bias is converted to a lapse rate by dividing by elevation difference (between model grid and true station elevation) and multiplying by 1000. The mode (given in legend and plotted in bottom row) is found by optimizing the KDEs (shown in top row).
#+CAPTION: **Top**: KDE estimates of distribution of 2m temperature errors split according to 1) whether grid location is above or below true station location, 2) distance from shore, and 3) time of day. 'Inland' is everything > 5km from shore is given by the finest model domain ('d03_op').
#+CAPTION: **Bottom**: Mode of distributions computed by numerical optimization of KDE, stratified by hour of day.
#+CAPTION: Vertical / horizontal grey lines give dry (9.8 $^{\circ}$K km$^{-1}$, hatched) and standard (6.5 $^{\circ}$K km$^{-1}$, points) lapse rates.

#+begin_src ipython :results silent :session
  a, a_l, a_s, b, b_l, b_s = partition(sea, dz['d03_orl'])

  lr = L['d03_orl']

  fig, axs = plt.subplots(2, 2, figsize=(15,10)) 

  topplot(axs[0, 0], '<')
  kplot(lr[b],'all')
  kplot(lr[b_l],'inland all')
  kplot(lr[b_l][lr.index.hour==0],'inland 0h')
  kplot(lr[b_l][lr.index.hour==12],'inland 12h')
  plt.legend()

  topplot(axs[0, 1], '>')
  kplot(lr[a],'all')
  kplot(lr[a_s],'coast all')
  kplot(lr[a_s][lr.index.hour==0],'coast 0h')
  kplot(lr[a_s][lr.index.hour==12],'coast 12h')
  plt.legend()

  botplot(axs[1, 0], lr[b], lr[b_l], 'inland')
  botplot(axs[1, 1], lr[a], lr[a_s], 'coast')
#+end_src

#+begin_src ipython :results silent :session
  a, a_l, a_s, b, b_l, b_s = partition(sea, dz['d03_1_00'])

  lr = L['d03_1_00']

  fig, axs = plt.subplots(2, 2, figsize=(15,10)) 

  topplot(axs[0, 0], '<')
  kplot(lr[b],'all')
  kplot(lr[b_l],'inland all')
  kplot(lr[b_l][lr.index.hour==0],'inland 0h')
  kplot(lr[b_l][lr.index.hour==12],'inland 12h')
  plt.legend()

  topplot(axs[0, 1], '>')
  kplot(lr[a],'all')
  kplot(lr[a_s],'coast all')
  kplot(lr[a_s][lr.index.hour==0],'coast 0h')
  kplot(lr[a_s][lr.index.hour==12],'coast 12h')
  plt.legend()

  botplot(axs[1, 0], lr[b], lr[b_l], 'inland')
  botplot(axs[1, 1], lr[a], lr[a_s], 'coast')
#+end_src

#+begin_src ipython :results silent :session
  from scipy.stats import binned_statistic

  def binned_plot(ax, x, values, color=None, label=None):
      me,b,n = binned_statistic(x,values,'mean',50)
      std = binned_statistic(x,values,np.nanstd,50)[0]
      xc = (b[:-1]+b[1:])/2
      ax.fill_betweenx(xc, me-2*std, me+2*std, color=color, alpha=.4)
      ax.plot(me, xc, color=color, label=label)

  def plot(t, tm, T2, zm, Z, sta):
      a = pd.concat((t, sta['elev']), axis=1, keys=['T','z']).sort_values('z')
      b = pd.concat((tm, Z), axis=1, keys=['T','z']).sort_values('z')
      c = pd.concat((tm - 0.0065 * (sta['elev']-Z), sta['elev']), axis=1, keys=['T','z']).sort_values('z')

      colors = plt.rcParams['axes.prop_cycle'].by_key()['color']
      fig, ax = plt.subplots(1, figsize=(12,8))
      binned_plot(ax, zm, T2, color=colors[0], label='model mean / elev')
      ax.scatter(b['T'],b['z'], marker='+', color=colors[1], label='model station loc no adj')
      ax.scatter(c['T'],c['z'], marker='+', color=colors[2], label='model station loc adj for 6.5 K/km')
      ax.scatter(a['T'],a['z'], marker='+', color=colors[3], label='observations')
      ax.set_xlabel('T [K]')
      ax.set_ylabel('elev [m]')
      ax.legend(loc=3)
#+end_src

#+begin_src ipython :results silent :session
  # model, complete field
  nc = Dataset('../../data/WRF/2d/d02_2014-09-10.nc')
  z = nc.variables['HGT'][:].flatten()

  # use only one year of data so as to not bias towards a particular season
  j = np.where(hh.get_time(nc)==np.datetime64('2014-12-31T00'))[0][0]
  T2 = nc.variables['T2'][j:,:,:].mean(0).flatten()
  nc.close()

  # use only one year of data, s.a.
  tm = Tm['d02']['2014-12-31':].mean()

  # average over the same day in different years to avoid bias towards those that occur more often
  t = T.groupby(T.index.dayofyear).mean().mean()

  plot(t, tm, T2, z, Z['d02'], sta)
#+end_src

#+CAPTION: Average 2m temperatures in observations and model (d02). Blue line and shade represents average and standard deviation of T2 binned according to elevation intervals. Orange crosses plot T2 at grid elevations, green crosses at corresponding station elevation after adjusting for 6.5 $^{\circ}$K km$^{-1}$ mean lapse rate.
#+CAPTION: **Question**: seasonality?

#+begin_src ipython :results silent :session
  # model, complete field
  nc = Dataset('../../data/WRF/3d/d03_day0.nc')
  z = nc.variables['HGT'][:].flatten()

  j = hh.tsplit(nc)
  T2_00 = nc.variables['T2'][:j,:,:].mean(0).flatten()
  #T2_12 = nc.variables['T2'][j:,:,:].mean(0).flatten()
  nc.close()

  # use only one year of data, s.a.
  tm = Tm['d03_0_00'].mean()

  # average over the same day in different years to avoid bias towards those that occur more often
  t = T.groupby(T.index.dayofyear).mean().mean()

  plot(t, tm, T2_00, z, Z['d03_0_00'], sta)
#+end_src

#+begin_src ipython :results silent :session
  from scipy.interpolate import interp1d
  from IGRAraw import extract
  import xarray as xr

  with pd.HDFStore('../../data/IGRA/IGRAraw.h5') as S:
      sta = S['sta']


  with xr.open_dataset('../../data/IGRA/IGRAmly.nc') as M:
      mly = M['temp']
      mly.load()

  with Dataset('../../data/WRF/2d/d02_2014-09-10_transf.nc') as nc:
      Map = mp.basemap(nc)
      t = hh.get_time(nc)
      T = nc.variables['temp'][:]
      P = nc.variables['press'][:]

  x, y = Map.xy()
  ij = Map(*hh.lonlat(sta.iloc[:2]))
#+end_src

#+begin_src ipython :results silent :session
  from IGRAraw import parse, get
  S = dict([(s, parse(get(s), 'TEMP')) for s in ['CIM00085586', 'ARM00087418']])
#+end_src

#+begin_src ipython :results silent :session
  Ti = ip.interp4D((x, y), T, ij, sta.iloc[:2].index, t, method='linear')
  Pi = ip.interp4D((x, y), P, ij, sta.iloc[:2].index, t, method='linear')
#+end_src

#+begin_src ipython :results silent :session
  p = [1000, 925, 850, 700, 500, 400, 300, 250, 200, 150, 100, 70, 50]
  # pressure is given in Pa instead of hPa in data
  pl = np.log(p) + np.log(100)

  m = mly.sel(type='value').mean(['month', 'hour']) * 0.1 + 273.15


  # for IGRA data - pressures in index of DataFrame
  def interp_0(pl, x):
      try:
          return interp1d(
              np.log(x.index), x, 'linear', bounds_error=False)(pl) * .1 + 273.15
      except:
          return np.repeat(np.nan, len(pl))

  def interp_1(pl, x):
      x = x.dropna()
      try:
          return pd.Series(interp1d(
              x.index, x, 'linear', bounds_error=False)(pl) * .1 + 273.15, index=p)
      except:
          return pd.Series(np.repeat(np.nan, len(p)), index=p)

  # for data from netCDF files - no potential missing, pressures in separate variable
  def interp_2(pl, P, T, j):
      return interp1d(
          np.log(P.loc[j]), T.loc[j], 'linear', bounds_error=False)(pl)


  def interp(raw, P, T):
      st = raw.replace({-9999: np.nan, -8888: np.nan})
      st.columns = np.log(st.columns)
      # initialize interpolation function with pressure levels
      obs = st.apply(partial(interp_1, pl), 1)
      # initialize interpolation function with pressure levels and data
      intp = partial(interp_2, pl, P, T)
      mod = pd.DataFrame([intp(j) for j in t], index=t, columns=p)
      return obs, mod

  def plot(ax, obs, mod, mly):
      dt = mod - obs
      (lambda y: ax.scatter(y, y.index.get_level_values(1)))(dt.stack())
      (lambda y: ax.plot(y, y.index, '-r', label='raw'))(dt.mean())
      (lambda y: ax.plot(y, y.index, '-g', label='monthly')
       )(mod.mean() - mly)
      ax.invert_yaxis()
      ax.grid(which='minor')
      ax.legend()
      ax.set_yscale('log')
      ax.set_ylim((1050, 90))


  fig, ax = plt.subplots(1, 2, figsize=(15, 8))
  for i, s in enumerate(['CIM00085586', 'ARM00087418']):
      obs, mod = interp(S[s], Pi[s], Ti[s])
      plot(ax[i], obs, mod, m.sel(loc=s).to_series())

  ylim = np.array([a.get_ylim() for a in ax])
  for a in ax:
      a.set_ylim((ylim.max(), ylim.min()))
  ax[0].set_title('St Domingo')
  ax[1].set_title('Mendoza')
  ax[1].set_yticklabels([])
#+end_src

#+begin_src ipython :results silent :session
  from matplotlib import cm, colors

  def id(x):
      x.index = x.index.date
      return x

  sm = cm.ScalarMappable(norm=colors.Normalize(vmin=p[-1], vmax=p[0]))
  sm.set_array(p)
  sm.set_cmap('gnuplot_r')
  fig, ax = plt.subplots(2, 2, figsize=(15,10), 
                         subplotpars=SubplotParams(left=0.10, right=0.86))
  for i, s in enumerate(['CIM00085586', 'ARM00087418']):
      obs, mod = interp(S[s], Pi[s], Ti[s])
      dt = id(obs[obs.index.hour == 12]) - id(obs[obs.index.hour == 0])
      x = np.linspace(-10, 10, 100)

      for j in p:
          try:
              g = gaussian_kde(dt[j].dropna())
          except:
              pass
          else:
              ax[0, i].plot(x, g(x), color=sm.to_rgba(j))
      ax[0, i].grid()
      ax[0, i].set_xticklabels([])

      dt = mod - obs
      for j in p:
          try:
              g = gaussian_kde(dt[j].dropna())
          except:
              pass
          else:
              ax[1, i].plot(x, g(x), color=sm.to_rgba(j))
      ax[1, i].grid()

  ax[0, 0].set_title('St Domingo')
  ax[0, 1].set_title('Mendoza')
  b1 = ax[0, 1].get_position()
  b2 = ax[1, 1].get_position()
  cb = plt.colorbar(
      sm, cax=fig.add_axes([b1.x1 + 0.04, b2.y0, 0.02, b1.y1 - b2.y0]))
  cb.ax.invert_yaxis()
#+end_src

#+CAPTION: **Top**: KDEs of daily cycle amplitudes for various pressure levels (colors), from radiosonde data. Daily cycle is computed as the temperature difference between the 0:00h and 12:00h soundings.  
#+CAPTION: **Bottom**: KDEs of model errors w.r.t. radio soundings
